{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# name : fady raafat aziz elgawly\n# email : fadyraafatelgawly@gmail.com","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-29T14:52:39.091437Z","iopub.execute_input":"2022-07-29T14:52:39.092654Z","iopub.status.idle":"2022-07-29T14:52:39.100465Z","shell.execute_reply.started":"2022-07-29T14:52:39.092557Z","shell.execute_reply":"2022-07-29T14:52:39.098962Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split,GridSearchCV, RepeatedStratifiedKFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom scipy.stats import chi2_contingency\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:39.111070Z","iopub.execute_input":"2022-07-29T14:52:39.112299Z","iopub.status.idle":"2022-07-29T14:52:39.747077Z","shell.execute_reply.started":"2022-07-29T14:52:39.112268Z","shell.execute_reply":"2022-07-29T14:52:39.745778Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#import data\ndf = pd.read_csv('../input/loan-data-2007-2014/loan_data_2007_2014/loan_data_2007_2014.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:39.749235Z","iopub.execute_input":"2022-07-29T14:52:39.749788Z","iopub.status.idle":"2022-07-29T14:52:45.097630Z","shell.execute_reply.started":"2022-07-29T14:52:39.749740Z","shell.execute_reply":"2022-07-29T14:52:45.096293Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Explorotary Data Analysis","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:45.103124Z","iopub.execute_input":"2022-07-29T14:52:45.104130Z","iopub.status.idle":"2022-07-29T14:52:45.110958Z","shell.execute_reply.started":"2022-07-29T14:52:45.104086Z","shell.execute_reply":"2022-07-29T14:52:45.109370Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:45.113324Z","iopub.execute_input":"2022-07-29T14:52:45.114520Z","iopub.status.idle":"2022-07-29T14:52:45.158412Z","shell.execute_reply.started":"2022-07-29T14:52:45.114458Z","shell.execute_reply":"2022-07-29T14:52:45.157113Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:45.160028Z","iopub.execute_input":"2022-07-29T14:52:45.160878Z","iopub.status.idle":"2022-07-29T14:52:45.172786Z","shell.execute_reply.started":"2022-07-29T14:52:45.160830Z","shell.execute_reply":"2022-07-29T14:52:45.170980Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#visualize null columns to drop them\ndf.isna().sum().reset_index(name=\"n\").plot.bar(x='index', y='n', rot=45)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:45.174990Z","iopub.execute_input":"2022-07-29T14:52:45.175673Z","iopub.status.idle":"2022-07-29T14:52:47.337598Z","shell.execute_reply.started":"2022-07-29T14:52:45.175477Z","shell.execute_reply":"2022-07-29T14:52:47.336045Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#sum of null rows in each column\ndf.isnull().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:47.339932Z","iopub.execute_input":"2022-07-29T14:52:47.340487Z","iopub.status.idle":"2022-07-29T14:52:48.240060Z","shell.execute_reply.started":"2022-07-29T14:52:47.340425Z","shell.execute_reply":"2022-07-29T14:52:48.238424Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# data frame shape\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:48.242185Z","iopub.execute_input":"2022-07-29T14:52:48.242714Z","iopub.status.idle":"2022-07-29T14:52:48.252121Z","shell.execute_reply.started":"2022-07-29T14:52:48.242669Z","shell.execute_reply":"2022-07-29T14:52:48.250592Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# drop columns with more than 80% null values\ndf.dropna(thresh = df.shape[0]*0.2, how = 'all', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:48.254569Z","iopub.execute_input":"2022-07-29T14:52:48.255162Z","iopub.status.idle":"2022-07-29T14:52:49.294092Z","shell.execute_reply.started":"2022-07-29T14:52:48.255103Z","shell.execute_reply":"2022-07-29T14:52:49.292574Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.296259Z","iopub.execute_input":"2022-07-29T14:52:49.297007Z","iopub.status.idle":"2022-07-29T14:52:49.334393Z","shell.execute_reply.started":"2022-07-29T14:52:49.296948Z","shell.execute_reply":"2022-07-29T14:52:49.333049Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#drop all redundant and forward-looking columns\ndf.drop(columns = ['Unnamed: 0','id', 'member_id', 'sub_grade', 'emp_title', 'url', 'desc', 'title',\n                          'zip_code', 'next_pymnt_d', 'recoveries', 'collection_recovery_fee',\n                          'total_rec_prncp', 'total_rec_late_fee'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.336579Z","iopub.execute_input":"2022-07-29T14:52:49.337421Z","iopub.status.idle":"2022-07-29T14:52:49.444502Z","shell.execute_reply.started":"2022-07-29T14:52:49.337379Z","shell.execute_reply":"2022-07-29T14:52:49.443041Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.452231Z","iopub.execute_input":"2022-07-29T14:52:49.452542Z","iopub.status.idle":"2022-07-29T14:52:49.490365Z","shell.execute_reply.started":"2022-07-29T14:52:49.452514Z","shell.execute_reply":"2022-07-29T14:52:49.489116Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# explore the unique values in loan_status column\ndf['loan_status'].value_counts(normalize = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.492190Z","iopub.execute_input":"2022-07-29T14:52:49.492803Z","iopub.status.idle":"2022-07-29T14:52:49.568594Z","shell.execute_reply.started":"2022-07-29T14:52:49.492762Z","shell.execute_reply":"2022-07-29T14:52:49.567153Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# create a new column based on the loan_status column that will be our target variable\ndf['loan_status'] = np.where(df[\"loan_status\"].isin(['Charged Off', 'Default',\n                                                                       'Late (31-120 days)',\n                                                                       'Does not meet the credit policy. Status:Charged Off']), 0, 1)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.570381Z","iopub.execute_input":"2022-07-29T14:52:49.571702Z","iopub.status.idle":"2022-07-29T14:52:49.633323Z","shell.execute_reply.started":"2022-07-29T14:52:49.571660Z","shell.execute_reply":"2022-07-29T14:52:49.632052Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#show our new column\ndf['loan_status']","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.636038Z","iopub.execute_input":"2022-07-29T14:52:49.636452Z","iopub.status.idle":"2022-07-29T14:52:49.647000Z","shell.execute_reply.started":"2022-07-29T14:52:49.636406Z","shell.execute_reply":"2022-07-29T14:52:49.645575Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:49.648893Z","iopub.execute_input":"2022-07-29T14:52:49.650378Z","iopub.status.idle":"2022-07-29T14:52:50.247457Z","shell.execute_reply.started":"2022-07-29T14:52:49.650334Z","shell.execute_reply":"2022-07-29T14:52:50.244646Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#visualize some columns\n# sns.set(style = 'ticks', color_codes=True)\n# sns.pairplot(data=df, hue='loan_status',  \n#              vars=['tot_coll_amt',\n#                                           'annual_inc',\n#                                           'loan_amnt',\n#                                           'int_rate', 'dti','installment','funded_amnt','out_prncp','delinq_2yrs','inq_last_6mths','mths_since_last_delinq',\n#                   'open_acc','pub_rec','total_acc','total_pymnt','last_pymnt_amnt'])","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:50.249743Z","iopub.execute_input":"2022-07-29T14:52:50.250354Z","iopub.status.idle":"2022-07-29T14:52:50.256646Z","shell.execute_reply.started":"2022-07-29T14:52:50.250291Z","shell.execute_reply":"2022-07-29T14:52:50.255252Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# pairplot of some numerical features together\nsns.set(style = 'ticks', color_codes=True)\nsns.pairplot(data=df, hue='loan_status',  \n             vars=['tot_coll_amt',\n                                          'annual_inc',\n                                          'loan_amnt',\n                                          'int_rate', 'dti'])","metadata":{"execution":{"iopub.status.busy":"2022-07-29T14:52:50.258648Z","iopub.execute_input":"2022-07-29T14:52:50.259658Z","iopub.status.idle":"2022-07-29T15:01:05.861343Z","shell.execute_reply.started":"2022-07-29T14:52:50.259598Z","shell.execute_reply":"2022-07-29T15:01:05.860174Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# countplot for target feature\nsns.countplot(data=df, x='loan_status')","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:01:05.863350Z","iopub.execute_input":"2022-07-29T15:01:05.863850Z","iopub.status.idle":"2022-07-29T15:01:06.083112Z","shell.execute_reply.started":"2022-07-29T15:01:05.863797Z","shell.execute_reply":"2022-07-29T15:01:06.081686Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(4,2, figsize=(16,16))\nsns.distplot(df.tot_coll_amt, bins = 20, ax=ax[0,0]) \nsns.distplot(df.annual_inc, bins = 20, ax=ax[0,1]) \nsns.distplot(df.installment, bins = 20, ax=ax[1,0]) \nsns.distplot(df.dti, bins = 20, ax=ax[1,1]) \nsns.distplot(df.out_prncp, bins = 20, ax=ax[2,0])\nsns.distplot(df.inq_last_6mths, bins = 20, ax=ax[2,1])\nsns.distplot(df.total_acc, bins = 20, ax=ax[3,0]) \nsns.distplot(df.last_pymnt_amnt, bins = 20, ax=ax[3,1]) ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:01:06.084895Z","iopub.execute_input":"2022-07-29T15:01:06.085327Z","iopub.status.idle":"2022-07-29T15:01:21.209328Z","shell.execute_reply.started":"2022-07-29T15:01:06.085298Z","shell.execute_reply":"2022-07-29T15:01:21.207967Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"## Pie Plots for categorical features\ndf2 = df[['term', 'grade', 'emp_length',\n                    'home_ownership', 'verification_status', 'issue_d',\n                    'pymnt_plan', 'purpose', 'addr_state','earliest_cr_line','initial_list_status','last_pymnt_d','last_credit_pull_d',\n                                'application_type']]\nfig = plt.figure(figsize=(25, 25))\nplt.suptitle('Pie Chart Distributions', fontsize=20)\nfor i in range(1, df2.shape[1] + 1):\n    plt.subplot(6, 3, i)\n    f = plt.gca()\n    f.axes.get_yaxis().set_visible(False)\n    f.set_title(df2.columns.values[i - 1])\n   \n    values = df2.iloc[:, i - 1].value_counts(normalize = True).values\n    index = df2.iloc[:, i - 1].value_counts(normalize = True).index\n    plt.pie(values, labels = index, autopct='%1.1f%%')\n    plt.axis('equal')\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:10:30.392760Z","iopub.execute_input":"2022-07-29T15:10:30.393135Z","iopub.status.idle":"2022-07-29T15:10:54.013235Z","shell.execute_reply.started":"2022-07-29T15:10:30.393106Z","shell.execute_reply":"2022-07-29T15:10:54.012104Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# split data into 80/20 while keeping the distribution of bad loans in test set same as that in the pre-split dataset\nX = df.drop([\"loan_status\"], axis=1)\ny = df[\"loan_status\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n                                                    random_state = 42, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:06.481851Z","iopub.execute_input":"2022-07-29T15:11:06.482311Z","iopub.status.idle":"2022-07-29T15:11:06.993804Z","shell.execute_reply.started":"2022-07-29T15:11:06.482278Z","shell.execute_reply":"2022-07-29T15:11:06.992514Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#Correlation with independent variable\nX.corrwith(df.loan_status).plot.bar(figsize = (15, 10), title = \"Correlation with Target\", fontsize = 10,grid = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:06.996658Z","iopub.execute_input":"2022-07-29T15:11:06.997254Z","iopub.status.idle":"2022-07-29T15:11:07.582798Z","shell.execute_reply.started":"2022-07-29T15:11:06.997208Z","shell.execute_reply":"2022-07-29T15:11:07.581280Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# hard copy the X datasets to avoid Pandas' SetttingWithCopyWarning when we play around with this data later on.\n# this is currently an open issue between Pandas and Scikit-Learn teams\nX_train, X_test = X_train.copy(), X_test.copy()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.584656Z","iopub.execute_input":"2022-07-29T15:11:07.585514Z","iopub.status.idle":"2022-07-29T15:11:07.734320Z","shell.execute_reply.started":"2022-07-29T15:11:07.585451Z","shell.execute_reply":"2022-07-29T15:11:07.732927Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.739257Z","iopub.execute_input":"2022-07-29T15:11:07.740278Z","iopub.status.idle":"2022-07-29T15:11:07.780497Z","shell.execute_reply.started":"2022-07-29T15:11:07.740231Z","shell.execute_reply":"2022-07-29T15:11:07.779151Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# visulaizing emp length\nX_train['emp_length'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.783858Z","iopub.execute_input":"2022-07-29T15:11:07.784322Z","iopub.status.idle":"2022-07-29T15:11:07.846839Z","shell.execute_reply.started":"2022-07-29T15:11:07.784274Z","shell.execute_reply":"2022-07-29T15:11:07.845705Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# visulaizing emp length\nX_train['term'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.848473Z","iopub.execute_input":"2022-07-29T15:11:07.848843Z","iopub.status.idle":"2022-07-29T15:11:07.906150Z","shell.execute_reply.started":"2022-07-29T15:11:07.848814Z","shell.execute_reply":"2022-07-29T15:11:07.904878Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Data Cleaning","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.908142Z","iopub.execute_input":"2022-07-29T15:11:07.908582Z","iopub.status.idle":"2022-07-29T15:11:07.914893Z","shell.execute_reply.started":"2022-07-29T15:11:07.908535Z","shell.execute_reply":"2022-07-29T15:11:07.913493Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# function to clean up the emp_length column, assign 0 to NANs, and convert to numeric\ndef emp_length_converter(df, column):\n    df[column] = df[column].str.replace('\\+ years', '')\n    df[column] = df[column].str.replace('< 1 year', str(0))\n    df[column] = df[column].str.replace(' years', '')\n    df[column] = df[column].str.replace(' year', '')\n    df[column] = pd.to_numeric(df[column])\n    df[column].fillna(value = 0, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.917266Z","iopub.execute_input":"2022-07-29T15:11:07.918188Z","iopub.status.idle":"2022-07-29T15:11:07.929596Z","shell.execute_reply.started":"2022-07-29T15:11:07.918145Z","shell.execute_reply":"2022-07-29T15:11:07.928199Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import datetime   \ndatetime.datetime.today().strftime(\"%Y-%m-%d\")","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.931694Z","iopub.execute_input":"2022-07-29T15:11:07.932251Z","iopub.status.idle":"2022-07-29T15:11:07.947598Z","shell.execute_reply.started":"2022-07-29T15:11:07.932207Z","shell.execute_reply":"2022-07-29T15:11:07.945973Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# function to convert date columns to datetime format and\n# create a new column as a difference between today and the respective date\ndef date_columns(df, column):\n    # store current month\n    today_date = pd.to_datetime('today').normalize()\n    # convert to datetime format\n    df[column] = pd.to_datetime(df[column], format = \"%b-%y\")\n    # calculate the difference in months and add to a new column\n    df['mths_since_' + column] = round(pd.to_numeric((today_date - df[column]) / np.timedelta64(1, 'M')))\n    # make any resulting -ve values to be equal to the max date\n    df['mths_since_' + column] = df['mths_since_' + column].apply(lambda x: df['mths_since_' + column].max() if x < 0 else x)\n    # drop the original date column\n    df.drop(columns = [column], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.954280Z","iopub.execute_input":"2022-07-29T15:11:07.954601Z","iopub.status.idle":"2022-07-29T15:11:07.965437Z","shell.execute_reply.started":"2022-07-29T15:11:07.954574Z","shell.execute_reply":"2022-07-29T15:11:07.964121Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# function to remove 'months' string from the 'term' column and convert it to numeric\ndef loan_term_converter(df, column):\n    df[column] = pd.to_numeric(df[column].str.replace(' months', ''))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.967810Z","iopub.execute_input":"2022-07-29T15:11:07.968358Z","iopub.status.idle":"2022-07-29T15:11:07.978751Z","shell.execute_reply.started":"2022-07-29T15:11:07.968315Z","shell.execute_reply":"2022-07-29T15:11:07.977084Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# apply these functions to X_train\ndate_columns(X_train, 'earliest_cr_line')\ndate_columns(X_train, 'issue_d')\ndate_columns(X_train, 'last_pymnt_d')\ndate_columns(X_train, 'last_credit_pull_d')\nemp_length_converter(X_train, 'emp_length')\nloan_term_converter(X_train, 'term')","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:07.981084Z","iopub.execute_input":"2022-07-29T15:11:07.981626Z","iopub.status.idle":"2022-07-29T15:11:13.163121Z","shell.execute_reply.started":"2022-07-29T15:11:07.981583Z","shell.execute_reply":"2022-07-29T15:11:13.161710Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Feature Selection","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:13.165042Z","iopub.execute_input":"2022-07-29T15:11:13.165631Z","iopub.status.idle":"2022-07-29T15:11:13.172177Z","shell.execute_reply.started":"2022-07-29T15:11:13.165557Z","shell.execute_reply":"2022-07-29T15:11:13.170672Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:13.174487Z","iopub.execute_input":"2022-07-29T15:11:13.175464Z","iopub.status.idle":"2022-07-29T15:11:13.500959Z","shell.execute_reply.started":"2022-07-29T15:11:13.175361Z","shell.execute_reply":"2022-07-29T15:11:13.499280Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# first divide training data into categorical and numerical subsets\nX_train_cat = X_train.select_dtypes(include = 'object').copy()\nX_train_num = X_train.select_dtypes(include = 'number').copy()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:13.502359Z","iopub.execute_input":"2022-07-29T15:11:13.502701Z","iopub.status.idle":"2022-07-29T15:11:13.696803Z","shell.execute_reply.started":"2022-07-29T15:11:13.502671Z","shell.execute_reply":"2022-07-29T15:11:13.695547Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#check that categorical columns have non null rows because if so we will drop the null rows\nX_train_cat.isnull().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:13.701687Z","iopub.execute_input":"2022-07-29T15:11:13.702300Z","iopub.status.idle":"2022-07-29T15:11:13.978170Z","shell.execute_reply.started":"2022-07-29T15:11:13.702267Z","shell.execute_reply":"2022-07-29T15:11:13.976204Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# calculate pair-wise correlations between them\ncorrmat = X_train_num.corr()\nplt.figure(figsize=(20,20))\nsns.heatmap(corrmat,annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:13.980331Z","iopub.execute_input":"2022-07-29T15:11:13.981070Z","iopub.status.idle":"2022-07-29T15:11:20.620642Z","shell.execute_reply.started":"2022-07-29T15:11:13.981025Z","shell.execute_reply":"2022-07-29T15:11:20.619214Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#visualize policy code\nX_train_num['policy_code']","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:20.622983Z","iopub.execute_input":"2022-07-29T15:11:20.623385Z","iopub.status.idle":"2022-07-29T15:11:20.635884Z","shell.execute_reply.started":"2022-07-29T15:11:20.623346Z","shell.execute_reply":"2022-07-29T15:11:20.634015Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# categorical feature selection","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:20.638512Z","iopub.execute_input":"2022-07-29T15:11:20.639827Z","iopub.status.idle":"2022-07-29T15:11:20.645415Z","shell.execute_reply.started":"2022-07-29T15:11:20.639751Z","shell.execute_reply":"2022-07-29T15:11:20.643772Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# define an empty dictionary to store chi-squared test results\nchi2_check = {}\n\n# loop over each column in the training set to calculate chi-statistic with the target variable\nfor column in X_train_cat:\n    chi, p, dof, ex = chi2_contingency(pd.crosstab(y_train, X_train_cat[column]))\n    chi2_check.setdefault('Feature',[]).append(column)\n    chi2_check.setdefault('p-value',[]).append(round(p, 10))\n\n# convert the dictionary to a DF\nchi2_result = pd.DataFrame(data = chi2_check)\nchi2_result.sort_values(by = ['p-value'], ascending = True, ignore_index = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:20.656837Z","iopub.execute_input":"2022-07-29T15:11:20.657598Z","iopub.status.idle":"2022-07-29T15:11:21.195949Z","shell.execute_reply.started":"2022-07-29T15:11:20.657537Z","shell.execute_reply":"2022-07-29T15:11:21.194605Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"chi2_result","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:21.197882Z","iopub.execute_input":"2022-07-29T15:11:21.198419Z","iopub.status.idle":"2022-07-29T15:11:21.216065Z","shell.execute_reply.started":"2022-07-29T15:11:21.198371Z","shell.execute_reply":"2022-07-29T15:11:21.214580Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# numerical feature selection","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:21.217820Z","iopub.execute_input":"2022-07-29T15:11:21.218754Z","iopub.status.idle":"2022-07-29T15:11:21.225228Z","shell.execute_reply.started":"2022-07-29T15:11:21.218631Z","shell.execute_reply":"2022-07-29T15:11:21.223428Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# since f_class_if does not accept missing values, we will do a very crude imputation of missing values\nX_train_num.fillna(X_train_num.mean(), inplace = True)\n\n# Calculate F Statistic and corresponding p values\nF_statistic, p_values = f_classif(X_train_num, y_train)\n\n# convert to a DF\nANOVA_F_table = pd.DataFrame(data = {'Numerical_Feature': X_train_num.columns.values,\n                                     'F-Score': F_statistic, 'p values': p_values.round(decimals=10)})\nANOVA_F_table.sort_values(by = ['F-Score'], ascending = False, ignore_index = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:21.226832Z","iopub.execute_input":"2022-07-29T15:11:21.227904Z","iopub.status.idle":"2022-07-29T15:11:21.628144Z","shell.execute_reply.started":"2022-07-29T15:11:21.227857Z","shell.execute_reply":"2022-07-29T15:11:21.626793Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"ANOVA_F_table","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:21.631334Z","iopub.execute_input":"2022-07-29T15:11:21.632324Z","iopub.status.idle":"2022-07-29T15:11:21.655688Z","shell.execute_reply.started":"2022-07-29T15:11:21.632279Z","shell.execute_reply":"2022-07-29T15:11:21.654240Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# save the top 20 numerical features in a list\ntop_num_features = ANOVA_F_table.iloc[:20,0].to_list()\n\n# calculate pair-wise correlations between them\ncorrmat = X_train_num[top_num_features].corr()\nplt.figure(figsize=(20,20))\nsns.heatmap(corrmat,annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:21.658292Z","iopub.execute_input":"2022-07-29T15:11:21.658981Z","iopub.status.idle":"2022-07-29T15:11:24.657876Z","shell.execute_reply.started":"2022-07-29T15:11:21.658607Z","shell.execute_reply":"2022-07-29T15:11:24.656112Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# A heat-map of these pair-wise correlations identifies two features (out_prncp_inv and total_pymnt_inv) \n# as highly correlated. Therefore, we will drop them also for our model","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.659964Z","iopub.execute_input":"2022-07-29T15:11:24.661384Z","iopub.status.idle":"2022-07-29T15:11:24.669172Z","shell.execute_reply.started":"2022-07-29T15:11:24.661288Z","shell.execute_reply":"2022-07-29T15:11:24.667468Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# save the names of columns to be dropped in a list\ndrop_columns_list = ANOVA_F_table.iloc[20:, 0].to_list()\ndrop_columns_list.extend(chi2_result.iloc[4:, 0].to_list())\ndrop_columns_list.extend(['out_prncp_inv', 'total_pymnt_inv'])","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.672022Z","iopub.execute_input":"2022-07-29T15:11:24.673800Z","iopub.status.idle":"2022-07-29T15:11:24.688970Z","shell.execute_reply.started":"2022-07-29T15:11:24.673705Z","shell.execute_reply":"2022-07-29T15:11:24.687230Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# apply to X_train\nX_train_subset = X_train.drop(columns = drop_columns_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.691292Z","iopub.execute_input":"2022-07-29T15:11:24.692412Z","iopub.status.idle":"2022-07-29T15:11:24.735920Z","shell.execute_reply.started":"2022-07-29T15:11:24.692366Z","shell.execute_reply":"2022-07-29T15:11:24.734018Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"X_train_subset.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.737997Z","iopub.execute_input":"2022-07-29T15:11:24.739515Z","iopub.status.idle":"2022-07-29T15:11:24.783560Z","shell.execute_reply.started":"2022-07-29T15:11:24.739468Z","shell.execute_reply":"2022-07-29T15:11:24.781968Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"X_train_subset.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.786004Z","iopub.execute_input":"2022-07-29T15:11:24.786873Z","iopub.status.idle":"2022-07-29T15:11:24.796704Z","shell.execute_reply.started":"2022-07-29T15:11:24.786829Z","shell.execute_reply":"2022-07-29T15:11:24.795155Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"X_train_subset.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.799575Z","iopub.execute_input":"2022-07-29T15:11:24.800546Z","iopub.status.idle":"2022-07-29T15:11:24.967668Z","shell.execute_reply.started":"2022-07-29T15:11:24.800498Z","shell.execute_reply":"2022-07-29T15:11:24.965933Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"num_cols = X_train_subset.select_dtypes(include = 'number').columns\nX_train_subset[num_cols]","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:24.970376Z","iopub.execute_input":"2022-07-29T15:11:24.970974Z","iopub.status.idle":"2022-07-29T15:11:25.067507Z","shell.execute_reply.started":"2022-07-29T15:11:24.970913Z","shell.execute_reply":"2022-07-29T15:11:25.066155Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# One-Hot Encoding and Update Test Dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:25.069608Z","iopub.execute_input":"2022-07-29T15:11:25.071222Z","iopub.status.idle":"2022-07-29T15:11:25.076469Z","shell.execute_reply.started":"2022-07-29T15:11:25.071188Z","shell.execute_reply":"2022-07-29T15:11:25.075029Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# function to create dummy variables\ndef dummy_creation(df, columns_list):\n    df_dummies = []\n    for col in columns_list:\n        df_dummies.append(pd.get_dummies(df[col], prefix = col, prefix_sep = ':'))\n    df_dummies = pd.concat(df_dummies, axis = 1)\n    df = pd.concat([df, df_dummies], axis = 1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:25.078918Z","iopub.execute_input":"2022-07-29T15:11:25.080595Z","iopub.status.idle":"2022-07-29T15:11:25.091576Z","shell.execute_reply.started":"2022-07-29T15:11:25.080551Z","shell.execute_reply":"2022-07-29T15:11:25.089822Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# apply to our final four categorical variables\nX_train_subset = dummy_creation(X_train_subset, ['grade', 'home_ownership', 'verification_status', 'purpose'])","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:25.093701Z","iopub.execute_input":"2022-07-29T15:11:25.095066Z","iopub.status.idle":"2022-07-29T15:11:25.325376Z","shell.execute_reply.started":"2022-07-29T15:11:25.095021Z","shell.execute_reply":"2022-07-29T15:11:25.323810Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"X_train_subset","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:25.328537Z","iopub.execute_input":"2022-07-29T15:11:25.329520Z","iopub.status.idle":"2022-07-29T15:11:25.434017Z","shell.execute_reply.started":"2022-07-29T15:11:25.329450Z","shell.execute_reply":"2022-07-29T15:11:25.431685Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"X_train_subset.columns","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:25.436620Z","iopub.execute_input":"2022-07-29T15:11:25.437489Z","iopub.status.idle":"2022-07-29T15:11:25.448884Z","shell.execute_reply.started":"2022-07-29T15:11:25.437424Z","shell.execute_reply":"2022-07-29T15:11:25.446756Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# update the test data with all functions defined so far\nemp_length_converter(X_test, 'emp_length')\ndate_columns(X_test, 'earliest_cr_line')\ndate_columns(X_test, 'issue_d')\ndate_columns(X_test, 'last_pymnt_d')\ndate_columns(X_test, 'last_credit_pull_d')\nloan_term_converter(X_test, 'term')\nX_test_subset = X_test.drop(columns = drop_columns_list)\nX_test_subset = dummy_creation(X_test_subset, ['grade', 'home_ownership', 'verification_status', 'purpose'])\n# reindex the dummied test set variables to make sure all the feature columns in the training set are also available in the test set\nX_test_subset = X_test_subset.reindex(labels=X_train_subset.columns, axis=1, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:25.451502Z","iopub.execute_input":"2022-07-29T15:11:25.455234Z","iopub.status.idle":"2022-07-29T15:11:26.584680Z","shell.execute_reply.started":"2022-07-29T15:11:25.455173Z","shell.execute_reply":"2022-07-29T15:11:26.582953Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# function to calculate WoE and IV of categorical features\n# The function takes 3 arguments: a dataframe (X_train_prepr), a string (column name), and a dataframe (y_train_prepr).\ndef woe_discrete(df, cat_variabe_name, y_df):\n    df = pd.concat([df[cat_variabe_name], y_df], axis = 1)\n    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n    df = df.iloc[:, [0, 1, 3]]\n    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n    df['n_good'] = df['prop_good'] * df['n_obs']\n    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n    df = df.sort_values(['WoE'])\n    df = df.reset_index(drop = True)\n    df['diff_prop_good'] = df['prop_good'].diff().abs()\n    df['diff_WoE'] = df['WoE'].diff().abs()\n    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n    df['IV'] = df['IV'].sum()\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:26.587325Z","iopub.execute_input":"2022-07-29T15:11:26.587809Z","iopub.status.idle":"2022-07-29T15:11:26.603894Z","shell.execute_reply.started":"2022-07-29T15:11:26.587762Z","shell.execute_reply":"2022-07-29T15:11:26.601945Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"grade_df = woe_discrete(X_train_subset, 'grade', y_train)\ngrade_df ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:26.607438Z","iopub.execute_input":"2022-07-29T15:11:26.608531Z","iopub.status.idle":"2022-07-29T15:11:26.714805Z","shell.execute_reply.started":"2022-07-29T15:11:26.608483Z","shell.execute_reply":"2022-07-29T15:11:26.713210Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# We set the default style of the graphs to the seaborn style. \nsns.set()\n# function to plot WoE value\ndef plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n    x = np.array(df_WoE.iloc[:, 0].apply(str))\n    y = df_WoE['WoE']\n    plt.figure(figsize=(18, 6))\n    plt.plot(x, y, marker = 'o', linestyle = '--', color = 'k')\n    plt.xlabel(df_WoE.columns[0])\n    plt.ylabel('Weight of Evidence')\n    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n    plt.xticks(rotation = rotation_of_x_axis_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:26.716978Z","iopub.execute_input":"2022-07-29T15:11:26.717609Z","iopub.status.idle":"2022-07-29T15:11:26.728504Z","shell.execute_reply.started":"2022-07-29T15:11:26.717536Z","shell.execute_reply":"2022-07-29T15:11:26.727063Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"plot_by_woe(grade_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:26.731348Z","iopub.execute_input":"2022-07-29T15:11:26.731999Z","iopub.status.idle":"2022-07-29T15:11:26.995513Z","shell.execute_reply.started":"2022-07-29T15:11:26.731957Z","shell.execute_reply":"2022-07-29T15:11:26.994072Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"verification_status_df = woe_discrete(X_train_subset, 'verification_status', y_train)\nverification_status_df ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:26.998729Z","iopub.execute_input":"2022-07-29T15:11:26.999162Z","iopub.status.idle":"2022-07-29T15:11:27.107186Z","shell.execute_reply.started":"2022-07-29T15:11:26.999103Z","shell.execute_reply":"2022-07-29T15:11:27.105519Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"plot_by_woe(verification_status_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:27.109093Z","iopub.execute_input":"2022-07-29T15:11:27.109613Z","iopub.status.idle":"2022-07-29T15:11:27.343411Z","shell.execute_reply.started":"2022-07-29T15:11:27.109569Z","shell.execute_reply":"2022-07-29T15:11:27.341941Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"home_ownership_df = woe_discrete(X_train_subset, 'home_ownership', y_train)\nhome_ownership_df ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:27.345882Z","iopub.execute_input":"2022-07-29T15:11:27.347202Z","iopub.status.idle":"2022-07-29T15:11:27.448833Z","shell.execute_reply.started":"2022-07-29T15:11:27.347117Z","shell.execute_reply":"2022-07-29T15:11:27.447343Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"plot_by_woe(home_ownership_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:27.451605Z","iopub.execute_input":"2022-07-29T15:11:27.452406Z","iopub.status.idle":"2022-07-29T15:11:27.686489Z","shell.execute_reply.started":"2022-07-29T15:11:27.452361Z","shell.execute_reply":"2022-07-29T15:11:27.685014Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"purpose_df = woe_discrete(X_train_subset, 'purpose', y_train)\npurpose_df ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:27.701584Z","iopub.execute_input":"2022-07-29T15:11:27.702219Z","iopub.status.idle":"2022-07-29T15:11:27.815652Z","shell.execute_reply.started":"2022-07-29T15:11:27.702185Z","shell.execute_reply":"2022-07-29T15:11:27.814191Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"plot_by_woe(purpose_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:27.817630Z","iopub.execute_input":"2022-07-29T15:11:27.818185Z","iopub.status.idle":"2022-07-29T15:11:28.146805Z","shell.execute_reply.started":"2022-07-29T15:11:27.818127Z","shell.execute_reply":"2022-07-29T15:11:28.145543Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# function to calculate WoE & IV of continuous variables\n# This is same as the function we defined earlier for discrete variables\n# The only difference are the 2 commented lines of code in the function that results in the df\n# being sorted by continuous variable values\n\ndef woe_ordered_continuous(df, continuous_variabe_name, y_df):\n    df = pd.concat([df[continuous_variabe_name], y_df], axis = 1)\n    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n    df = df.iloc[:, [0, 1, 3]]\n    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n    df['n_good'] = df['prop_good'] * df['n_obs']\n    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n    #df = df.sort_values(['WoE'])\n    #df = df.reset_index(drop = True)\n    df['diff_prop_good'] = df['prop_good'].diff().abs()\n    df['diff_WoE'] = df['WoE'].diff().abs()\n    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n    df['IV'] = df['IV'].sum()\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:28.148629Z","iopub.execute_input":"2022-07-29T15:11:28.150244Z","iopub.status.idle":"2022-07-29T15:11:28.165517Z","shell.execute_reply.started":"2022-07-29T15:11:28.150197Z","shell.execute_reply":"2022-07-29T15:11:28.164194Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"term_df = woe_ordered_continuous(X_train_subset, 'term', y_train)\nterm_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:28.167598Z","iopub.execute_input":"2022-07-29T15:11:28.168120Z","iopub.status.idle":"2022-07-29T15:11:28.219010Z","shell.execute_reply.started":"2022-07-29T15:11:28.168076Z","shell.execute_reply":"2022-07-29T15:11:28.217493Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"plot_by_woe(term_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:28.220854Z","iopub.execute_input":"2022-07-29T15:11:28.221359Z","iopub.status.idle":"2022-07-29T15:11:28.427834Z","shell.execute_reply.started":"2022-07-29T15:11:28.221314Z","shell.execute_reply":"2022-07-29T15:11:28.426766Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"int_rate_df = woe_ordered_continuous(X_train_subset, 'int_rate', y_train)\nint_rate_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:28.429972Z","iopub.execute_input":"2022-07-29T15:11:28.430416Z","iopub.status.idle":"2022-07-29T15:11:28.495600Z","shell.execute_reply.started":"2022-07-29T15:11:28.430376Z","shell.execute_reply":"2022-07-29T15:11:28.493938Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"plot_by_woe(int_rate_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:28.497317Z","iopub.execute_input":"2022-07-29T15:11:28.498516Z","iopub.status.idle":"2022-07-29T15:11:41.308405Z","shell.execute_reply.started":"2022-07-29T15:11:28.498485Z","shell.execute_reply":"2022-07-29T15:11:41.307086Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"annual_inc_df = woe_ordered_continuous(X_train_subset, 'annual_inc', y_train)\nannual_inc_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:41.310583Z","iopub.execute_input":"2022-07-29T15:11:41.311801Z","iopub.status.idle":"2022-07-29T15:11:41.393946Z","shell.execute_reply.started":"2022-07-29T15:11:41.311685Z","shell.execute_reply":"2022-07-29T15:11:41.392608Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"dti_df = woe_ordered_continuous(X_train_subset, 'dti', y_train)\ndti_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:41.395699Z","iopub.execute_input":"2022-07-29T15:11:41.397254Z","iopub.status.idle":"2022-07-29T15:11:41.468238Z","shell.execute_reply.started":"2022-07-29T15:11:41.397208Z","shell.execute_reply":"2022-07-29T15:11:41.466919Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"inq_last_6mths_df = woe_ordered_continuous(X_train_subset, 'inq_last_6mths', y_train)\ninq_last_6mths_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:41.470234Z","iopub.execute_input":"2022-07-29T15:11:41.471107Z","iopub.status.idle":"2022-07-29T15:11:41.539878Z","shell.execute_reply.started":"2022-07-29T15:11:41.471067Z","shell.execute_reply":"2022-07-29T15:11:41.538217Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"revol_util_df = woe_ordered_continuous(X_train_subset, 'revol_util', y_train)\nrevol_util_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:41.542218Z","iopub.execute_input":"2022-07-29T15:11:41.542739Z","iopub.status.idle":"2022-07-29T15:11:41.622599Z","shell.execute_reply.started":"2022-07-29T15:11:41.542699Z","shell.execute_reply":"2022-07-29T15:11:41.620444Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"out_prncp_df = woe_ordered_continuous(X_train_subset, 'out_prncp', y_train)\nout_prncp_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:41.624809Z","iopub.execute_input":"2022-07-29T15:11:41.625861Z","iopub.status.idle":"2022-07-29T15:11:41.763290Z","shell.execute_reply.started":"2022-07-29T15:11:41.625802Z","shell.execute_reply":"2022-07-29T15:11:41.761958Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"total_pymnt_df = woe_ordered_continuous(X_train_subset, 'total_pymnt', y_train)\ntotal_pymnt_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:41.765374Z","iopub.execute_input":"2022-07-29T15:11:41.765826Z","iopub.status.idle":"2022-07-29T15:11:42.023078Z","shell.execute_reply.started":"2022-07-29T15:11:41.765781Z","shell.execute_reply":"2022-07-29T15:11:42.021498Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"total_rec_int_df = woe_ordered_continuous(X_train_subset, 'total_rec_int', y_train)\ntotal_rec_int_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.024841Z","iopub.execute_input":"2022-07-29T15:11:42.025604Z","iopub.status.idle":"2022-07-29T15:11:42.237197Z","shell.execute_reply.started":"2022-07-29T15:11:42.025559Z","shell.execute_reply":"2022-07-29T15:11:42.235884Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"total_rev_hi_lim_df = woe_ordered_continuous(X_train_subset, 'total_rev_hi_lim', y_train)\ntotal_rev_hi_lim_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.239726Z","iopub.execute_input":"2022-07-29T15:11:42.240544Z","iopub.status.idle":"2022-07-29T15:11:42.313087Z","shell.execute_reply.started":"2022-07-29T15:11:42.240499Z","shell.execute_reply":"2022-07-29T15:11:42.311609Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"mths_since_earliest_cr_line_df = woe_ordered_continuous(X_train_subset, 'mths_since_earliest_cr_line', y_train)\nmths_since_earliest_cr_line_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.314795Z","iopub.execute_input":"2022-07-29T15:11:42.316084Z","iopub.status.idle":"2022-07-29T15:11:42.375417Z","shell.execute_reply.started":"2022-07-29T15:11:42.316041Z","shell.execute_reply":"2022-07-29T15:11:42.373678Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"mths_since_issue_d_df = woe_ordered_continuous(X_train_subset, 'mths_since_issue_d', y_train)\nmths_since_issue_d_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.378064Z","iopub.execute_input":"2022-07-29T15:11:42.378612Z","iopub.status.idle":"2022-07-29T15:11:42.438198Z","shell.execute_reply.started":"2022-07-29T15:11:42.378553Z","shell.execute_reply":"2022-07-29T15:11:42.436171Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"mths_since_issue_d_df = woe_ordered_continuous(X_train_subset, 'mths_since_last_credit_pull_d', y_train)\nmths_since_issue_d_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.440282Z","iopub.execute_input":"2022-07-29T15:11:42.440709Z","iopub.status.idle":"2022-07-29T15:11:42.500667Z","shell.execute_reply.started":"2022-07-29T15:11:42.440664Z","shell.execute_reply":"2022-07-29T15:11:42.499106Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"emp_length_df = woe_ordered_continuous(X_train_subset, 'emp_length', y_train)\nemp_length_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.503163Z","iopub.execute_input":"2022-07-29T15:11:42.503851Z","iopub.status.idle":"2022-07-29T15:11:42.557536Z","shell.execute_reply.started":"2022-07-29T15:11:42.503807Z","shell.execute_reply":"2022-07-29T15:11:42.556138Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"total_acc_df = woe_ordered_continuous(X_train_subset, 'total_acc', y_train)\ntotal_acc_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.558945Z","iopub.execute_input":"2022-07-29T15:11:42.559528Z","iopub.status.idle":"2022-07-29T15:11:42.620489Z","shell.execute_reply.started":"2022-07-29T15:11:42.559471Z","shell.execute_reply":"2022-07-29T15:11:42.618828Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"last_pymnt_amnt_df = woe_ordered_continuous(X_train_subset, 'last_pymnt_amnt', y_train)\nlast_pymnt_amnt_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.622664Z","iopub.execute_input":"2022-07-29T15:11:42.623532Z","iopub.status.idle":"2022-07-29T15:11:42.787023Z","shell.execute_reply.started":"2022-07-29T15:11:42.623484Z","shell.execute_reply":"2022-07-29T15:11:42.785551Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"tot_cur_bal_df = woe_ordered_continuous(X_train_subset, 'tot_cur_bal', y_train)\ntot_cur_bal_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.788815Z","iopub.execute_input":"2022-07-29T15:11:42.790024Z","iopub.status.idle":"2022-07-29T15:11:42.979847Z","shell.execute_reply.started":"2022-07-29T15:11:42.789977Z","shell.execute_reply":"2022-07-29T15:11:42.977374Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"mths_since_last_pymnt_d_df = woe_ordered_continuous(X_train_subset, 'mths_since_last_pymnt_d', y_train)\nmths_since_last_pymnt_d_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:42.981378Z","iopub.execute_input":"2022-07-29T15:11:42.981707Z","iopub.status.idle":"2022-07-29T15:11:43.049462Z","shell.execute_reply.started":"2022-07-29T15:11:42.981678Z","shell.execute_reply":"2022-07-29T15:11:43.047732Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# There is no need to combine WoE bins or create a separate missing category given the discrete and monotonic WoE and absence of any missing values: grade, verification_status, term\n# Combine WoE bins with very low observations with the neighboring bin: home_ownership, purpose\n# Combine WoE bins with similar WoE values together, potentially with a separate missing category: int_rate, annual_inc, dti, inq_last_6mths, revol_util, out_prncp, total_pymnt, total_rec_int, total_rev_hi_lim, mths_since_earliest_cr_line, mths_since_issue_d, mths_since_last_credit_pull_d\n# Ignore features with a low or very high IV value: emp_length, total_acc, last_pymnt_amnt, tot_cur_bal, mths_since_last_pymnt_d_factor","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.051026Z","iopub.execute_input":"2022-07-29T15:11:43.052314Z","iopub.status.idle":"2022-07-29T15:11:43.059165Z","shell.execute_reply.started":"2022-07-29T15:11:43.052270Z","shell.execute_reply":"2022-07-29T15:11:43.057555Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# create a list of all the reference categories, i.e. one category from each of the global features\nref_categories = ['mths_since_last_credit_pull_d:>75', 'mths_since_issue_d:>122', 'mths_since_earliest_cr_line:>434', 'total_rev_hi_lim:>79,780', \n                  'total_rec_int:>7,260', 'total_pymnt:>25,000', 'out_prncp:>15,437', 'revol_util:>1.0', 'inq_last_6mths:>4', 'dti:>35.191', \n                  'annual_inc:>150K', 'int_rate:>20.281', 'term:60', 'purpose:major_purch__car__home_impr', 'verification_status:Not Verified', \n                  'home_ownership:MORTGAGE', 'grade:G']\n\n# custom transformer class to create new categorical dummy features\nclass WoE_Binning(BaseEstimator, TransformerMixin):\n    def __init__(self, X): # no *args or *kargs\n        self.X = X\n    def fit(self, X, y = None):\n        return self #nothing else to do\n    def transform(self, X):\n        X_new = X.loc[:, 'grade:A': 'grade:G']\n        X_new['home_ownership:OWN'] = X.loc[:,'home_ownership:OWN']\n        X_new['home_ownership:MORTGAGE'] = X.loc[:,'home_ownership:MORTGAGE']\n        X_new['home_ownership:OTHER_NONE_RENT'] = sum([X['home_ownership:OTHER'], X['home_ownership:NONE'], X['home_ownership:RENT']])\n        X_new = pd.concat([X_new, X.loc[:, 'verification_status:Not Verified':'verification_status:Verified']], axis = 1)\n        X_new['purpose:debt_consolidation'] = X.loc[:,'purpose:debt_consolidation']\n        X_new['purpose:credit_card'] = X.loc[:,'purpose:credit_card']\n        X_new['purpose:major_purch__car__home_impr'] = sum([X['purpose:major_purchase'], X['purpose:car'], X['purpose:home_improvement']])\n        X_new['purpose:educ__ren_en__sm_b__mov'] = sum([X['purpose:educational'], X['purpose:renewable_energy'], X['purpose:small_business'], \n                                                        X['purpose:moving']])\n        X_new['purpose:vacation__house__wedding__med__oth'] = sum([X['purpose:vacation'], X['purpose:house'], X['purpose:wedding'], \n                                                                   X['purpose:medical'], X['purpose:other']])\n        X_new['term:36'] = np.where((X['term'] == 36), 1, 0)\n        X_new['term:60'] = np.where((X['term'] == 60), 1, 0)\n        X_new['int_rate:<7.071'] = np.where((X['int_rate'] <= 7.071), 1, 0)\n        X_new['int_rate:7.071-10.374'] = np.where((X['int_rate'] > 7.071) & (X['int_rate'] <= 10.374), 1, 0)\n        X_new['int_rate:10.374-13.676'] = np.where((X['int_rate'] > 10.374) & (X['int_rate'] <= 13.676), 1, 0)\n        X_new['int_rate:13.676-15.74'] = np.where((X['int_rate'] > 13.676) & (X['int_rate'] <= 15.74), 1, 0)\n        X_new['int_rate:15.74-20.281'] = np.where((X['int_rate'] > 15.74) & (X['int_rate'] <= 20.281), 1, 0)\n        X_new['int_rate:>20.281'] = np.where((X['int_rate'] > 20.281), 1, 0)\n        X_new['annual_inc:missing'] = np.where(X['annual_inc'].isnull(), 1, 0)\n        X_new['annual_inc:<28,555'] = np.where((X['annual_inc'] <= 28555), 1, 0)\n        X_new['annual_inc:28,555-37,440'] = np.where((X['annual_inc'] > 28555) & (X['annual_inc'] <= 37440), 1, 0)\n        X_new['annual_inc:37,440-61,137'] = np.where((X['annual_inc'] > 37440) & (X['annual_inc'] <= 61137), 1, 0)\n        X_new['annual_inc:61,137-81,872'] = np.where((X['annual_inc'] > 61137) & (X['annual_inc'] <= 81872), 1, 0)\n        X_new['annual_inc:81,872-102,606'] = np.where((X['annual_inc'] > 81872) & (X['annual_inc'] <= 102606), 1, 0)\n        X_new['annual_inc:102,606-120,379'] = np.where((X['annual_inc'] > 102606) & (X['annual_inc'] <= 120379), 1, 0)\n        X_new['annual_inc:120,379-150,000'] = np.where((X['annual_inc'] > 120379) & (X['annual_inc'] <= 150000), 1, 0)\n        X_new['annual_inc:>150K'] = np.where((X['annual_inc'] > 150000), 1, 0)\n        X_new['dti:<=1.6'] = np.where((X['dti'] <= 1.6), 1, 0)\n        X_new['dti:1.6-5.599'] = np.where((X['dti'] > 1.6) & (X['dti'] <= 5.599), 1, 0)\n        X_new['dti:5.599-10.397'] = np.where((X['dti'] > 5.599) & (X['dti'] <= 10.397), 1, 0)\n        X_new['dti:10.397-15.196'] = np.where((X['dti'] > 10.397) & (X['dti'] <= 15.196), 1, 0)\n        X_new['dti:15.196-19.195'] = np.where((X['dti'] > 15.196) & (X['dti'] <= 19.195), 1, 0)\n        X_new['dti:19.195-24.794'] = np.where((X['dti'] > 19.195) & (X['dti'] <= 24.794), 1, 0)\n        X_new['dti:24.794-35.191'] = np.where((X['dti'] > 24.794) & (X['dti'] <= 35.191), 1, 0)\n        X_new['dti:>35.191'] = np.where((X['dti'] > 35.191), 1, 0)\n        X_new['inq_last_6mths:missing'] = np.where(X['inq_last_6mths'].isnull(), 1, 0)\n        X_new['inq_last_6mths:0'] = np.where((X['inq_last_6mths'] == 0), 1, 0)\n        X_new['inq_last_6mths:1-2'] = np.where((X['inq_last_6mths'] >= 1) & (X['inq_last_6mths'] <= 2), 1, 0)\n        X_new['inq_last_6mths:3-4'] = np.where((X['inq_last_6mths'] >= 3) & (X['inq_last_6mths'] <= 4), 1, 0)\n        X_new['inq_last_6mths:>4'] = np.where((X['inq_last_6mths'] > 4), 1, 0)\n        X_new['revol_util:missing'] = np.where(X['revol_util'].isnull(), 1, 0)\n        X_new['revol_util:<0.1'] = np.where((X['revol_util'] <= 0.1), 1, 0)\n        X_new['revol_util:0.1-0.2'] = np.where((X['revol_util'] > 0.1) & (X['revol_util'] <= 0.2), 1, 0)\n        X_new['revol_util:0.2-0.3'] = np.where((X['revol_util'] > 0.2) & (X['revol_util'] <= 0.3), 1, 0)\n        X_new['revol_util:0.3-0.4'] = np.where((X['revol_util'] > 0.3) & (X['revol_util'] <= 0.4), 1, 0)\n        X_new['revol_util:0.4-0.5'] = np.where((X['revol_util'] > 0.4) & (X['revol_util'] <= 0.5), 1, 0)\n        X_new['revol_util:0.5-0.6'] = np.where((X['revol_util'] > 0.5) & (X['revol_util'] <= 0.6), 1, 0)\n        X_new['revol_util:0.6-0.7'] = np.where((X['revol_util'] > 0.6) & (X['revol_util'] <= 0.7), 1, 0)\n        X_new['revol_util:0.7-0.8'] = np.where((X['revol_util'] > 0.7) & (X['revol_util'] <= 0.8), 1, 0)\n        X_new['revol_util:0.8-0.9'] = np.where((X['revol_util'] > 0.8) & (X['revol_util'] <= 0.9), 1, 0)\n        X_new['revol_util:0.9-1.0'] = np.where((X['revol_util'] > 0.9) & (X['revol_util'] <= 1.0), 1, 0)\n        X_new['revol_util:>1.0'] = np.where((X['revol_util'] > 1.0), 1, 0)\n        X_new['out_prncp:<1,286'] = np.where((X['out_prncp'] <= 1286), 1, 0)\n        X_new['out_prncp:1,286-6,432'] = np.where((X['out_prncp'] > 1286) & (X['out_prncp'] <= 6432), 1, 0)\n        X_new['out_prncp:6,432-9,005'] = np.where((X['out_prncp'] > 6432) & (X['out_prncp'] <= 9005), 1, 0)\n        X_new['out_prncp:9,005-10,291'] = np.where((X['out_prncp'] > 9005) & (X['out_prncp'] <= 10291), 1, 0)\n        X_new['out_prncp:10,291-15,437'] = np.where((X['out_prncp'] > 10291) & (X['out_prncp'] <= 15437), 1, 0)\n        X_new['out_prncp:>15,437'] = np.where((X['out_prncp'] > 15437), 1, 0)\n        X_new['total_pymnt:<10,000'] = np.where((X['total_pymnt'] <= 10000), 1, 0)\n        X_new['total_pymnt:10,000-15,000'] = np.where((X['total_pymnt'] > 10000) & (X['total_pymnt'] <= 15000), 1, 0)\n        X_new['total_pymnt:15,000-20,000'] = np.where((X['total_pymnt'] > 15000) & (X['total_pymnt'] <= 20000), 1, 0)\n        X_new['total_pymnt:20,000-25,000'] = np.where((X['total_pymnt'] > 20000) & (X['total_pymnt'] <= 25000), 1, 0)\n        X_new['total_pymnt:>25,000'] = np.where((X['total_pymnt'] > 25000), 1, 0)\n        X_new['total_rec_int:<1,089'] = np.where((X['total_rec_int'] <= 1089), 1, 0)\n        X_new['total_rec_int:1,089-2,541'] = np.where((X['total_rec_int'] > 1089) & (X['total_rec_int'] <= 2541), 1, 0)\n        X_new['total_rec_int:2,541-4,719'] = np.where((X['total_rec_int'] > 2541) & (X['total_rec_int'] <= 4719), 1, 0)\n        X_new['total_rec_int:4,719-7,260'] = np.where((X['total_rec_int'] > 4719) & (X['total_rec_int'] <= 7260), 1, 0)\n        X_new['total_rec_int:>7,260'] = np.where((X['total_rec_int'] > 7260), 1, 0)\n        X_new['total_rev_hi_lim:missing'] = np.where(X['total_rev_hi_lim'].isnull(), 1, 0)\n        X_new['total_rev_hi_lim:<6,381'] = np.where((X['total_rev_hi_lim'] <= 6381), 1, 0)\n        X_new['total_rev_hi_lim:6,381-19,144'] = np.where((X['total_rev_hi_lim'] > 6381) & (X['total_rev_hi_lim'] <= 19144), 1, 0)\n        X_new['total_rev_hi_lim:19,144-25,525'] = np.where((X['total_rev_hi_lim'] > 19144) & (X['total_rev_hi_lim'] <= 25525), 1, 0)\n        X_new['total_rev_hi_lim:25,525-35,097'] = np.where((X['total_rev_hi_lim'] > 25525) & (X['total_rev_hi_lim'] <= 35097), 1, 0)\n        X_new['total_rev_hi_lim:35,097-54,241'] = np.where((X['total_rev_hi_lim'] > 35097) & (X['total_rev_hi_lim'] <= 54241), 1, 0)\n        X_new['total_rev_hi_lim:54,241-79,780'] = np.where((X['total_rev_hi_lim'] > 54241) & (X['total_rev_hi_lim'] <= 79780), 1, 0)\n        X_new['total_rev_hi_lim:>79,780'] = np.where((X['total_rev_hi_lim'] > 79780), 1, 0)\n        X_new['mths_since_earliest_cr_line:missing'] = np.where(X['mths_since_earliest_cr_line'].isnull(), 1, 0)\n        X_new['mths_since_earliest_cr_line:<125'] = np.where((X['mths_since_earliest_cr_line'] <= 125), 1, 0)\n        X_new['mths_since_earliest_cr_line:125-167'] = np.where((X['mths_since_earliest_cr_line'] > 125) & (X['mths_since_earliest_cr_line'] <= 167), 1, 0)\n        X_new['mths_since_earliest_cr_line:167-249'] = np.where((X['mths_since_earliest_cr_line'] > 167) & (X['mths_since_earliest_cr_line'] <= 249), 1, 0)\n        X_new['mths_since_earliest_cr_line:249-331'] = np.where((X['mths_since_earliest_cr_line'] > 249) & (X['mths_since_earliest_cr_line'] <= 331), 1, 0)\n        X_new['mths_since_earliest_cr_line:331-434'] = np.where((X['mths_since_earliest_cr_line'] > 331) & (X['mths_since_earliest_cr_line'] <= 434), 1, 0)\n        X_new['mths_since_earliest_cr_line:>434'] = np.where((X['mths_since_earliest_cr_line'] > 434), 1, 0)\n        X_new['mths_since_issue_d:<79'] = np.where((X['mths_since_issue_d'] <= 79), 1, 0)\n        X_new['mths_since_issue_d:79-89'] = np.where((X['mths_since_issue_d'] > 79) & (X['mths_since_issue_d'] <= 89), 1, 0)\n        X_new['mths_since_issue_d:89-100'] = np.where((X['mths_since_issue_d'] > 89) & (X['mths_since_issue_d'] <= 100), 1, 0)\n        X_new['mths_since_issue_d:100-122'] = np.where((X['mths_since_issue_d'] > 100) & (X['mths_since_issue_d'] <= 122), 1, 0)\n        X_new['mths_since_issue_d:>122'] = np.where((X['mths_since_issue_d'] > 122), 1, 0)\n        X_new['mths_since_last_credit_pull_d:missing'] = np.where(X['mths_since_last_credit_pull_d'].isnull(), 1, 0)\n        X_new['mths_since_last_credit_pull_d:<56'] = np.where((X['mths_since_last_credit_pull_d'] <= 56), 1, 0)\n        X_new['mths_since_last_credit_pull_d:56-61'] = np.where((X['mths_since_last_credit_pull_d'] > 56) & (X['mths_since_last_credit_pull_d'] <= 61), 1, 0)\n        X_new['mths_since_last_credit_pull_d:61-75'] = np.where((X['mths_since_last_credit_pull_d'] > 61) & (X['mths_since_last_credit_pull_d'] <= 75), 1, 0)\n        X_new['mths_since_last_credit_pull_d:>75'] = np.where((X['mths_since_last_credit_pull_d'] > 75), 1, 0)\n        X_new.drop(columns = ref_categories, inplace = True)\n        return X_new","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.061703Z","iopub.execute_input":"2022-07-29T15:11:43.062292Z","iopub.status.idle":"2022-07-29T15:11:43.449412Z","shell.execute_reply.started":"2022-07-29T15:11:43.062248Z","shell.execute_reply":"2022-07-29T15:11:43.447951Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.451624Z","iopub.execute_input":"2022-07-29T15:11:43.452322Z","iopub.status.idle":"2022-07-29T15:11:43.473141Z","shell.execute_reply.started":"2022-07-29T15:11:43.452252Z","shell.execute_reply":"2022-07-29T15:11:43.471517Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# Model Training","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.475492Z","iopub.execute_input":"2022-07-29T15:11:43.476523Z","iopub.status.idle":"2022-07-29T15:11:43.484863Z","shell.execute_reply.started":"2022-07-29T15:11:43.476481Z","shell.execute_reply":"2022-07-29T15:11:43.483672Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"#first i begin by hyperparameter tuning for logisitic regression to find best params","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.487379Z","iopub.execute_input":"2022-07-29T15:11:43.488335Z","iopub.status.idle":"2022-07-29T15:11:43.496316Z","shell.execute_reply.started":"2022-07-29T15:11:43.488292Z","shell.execute_reply":"2022-07-29T15:11:43.494916Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# define modeling pipeline i use the logistic regression to give me probabilities for credit scoring\n\n# reg = LogisticRegression(class_weight = 'balanced')\n# woe_transform = WoE_Binning(X)\n# pipeline = Pipeline(steps=[('woe', woe_transform), ('model', reg)])\n\n# # grid['model__penalty'] = ['l1', 'l2', 'elasticnet', 'none']\n# # grid['model__C'] = np.logspace(-4, 4, 20)\n# # grid['model__solver'] = ['lbfgs','newton-cg','liblinear','sag','saga']\n# # grid['model__max_iter'] = [100, 1000,2500, 5000]\n\n# param_grid = {\n#     'model__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n#     'model__C' : [0.0001, 0.001, 0.01, 0.1, 1, 10],\n#     'model__max_iter': [100, 1000,2500, 5000]\n# }\n\n# # define cross-validation criteria\n# cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=1)\n\n# # fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\n# # define the grid search\n# grid  = GridSearchCV(pipeline, param_grid=param_grid, scoring='roc_auc', cv=cv)\n# grid_result = grid.fit(X_train_subset,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.500284Z","iopub.execute_input":"2022-07-29T15:11:43.500695Z","iopub.status.idle":"2022-07-29T15:11:43.509354Z","shell.execute_reply.started":"2022-07-29T15:11:43.500660Z","shell.execute_reply":"2022-07-29T15:11:43.508037Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"# summarize results\n# print(\"Best Score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# print(\"Best estimator:  %s\" % (grid_result.best_estimator_))\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n# for mean, stdev, param in zip(means,stds,params):\n#      print(\"Mean = %f (std=%f) with: %r\" % (mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.511415Z","iopub.execute_input":"2022-07-29T15:11:43.512128Z","iopub.status.idle":"2022-07-29T15:11:43.526579Z","shell.execute_reply.started":"2022-07-29T15:11:43.512070Z","shell.execute_reply":"2022-07-29T15:11:43.525335Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# so the best params are max_iter=5000 ,C=1,penalty='l2' \n# i hashed them because it takes very very long time","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.528472Z","iopub.execute_input":"2022-07-29T15:11:43.530272Z","iopub.status.idle":"2022-07-29T15:11:43.537887Z","shell.execute_reply.started":"2022-07-29T15:11:43.530224Z","shell.execute_reply":"2022-07-29T15:11:43.536256Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# define modeling pipeline\nreg = LogisticRegression(max_iter=5000 , class_weight = 'balanced',C=1,penalty='l2')\nwoe_transform = WoE_Binning(X)\npipeline = Pipeline(steps=[('woe', woe_transform), ('model', reg)])\n\n# define cross-validation criteria\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\n# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\nscores = cross_val_score(pipeline, X_train_subset, y_train, scoring = 'roc_auc', cv = cv)\nAUROC = np.mean(scores)\nGINI = AUROC * 2 - 1\n\n# print the mean AUROC score and Gini\nprint('Mean AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (GINI))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:11:43.540632Z","iopub.execute_input":"2022-07-29T15:11:43.541350Z","iopub.status.idle":"2022-07-29T15:17:37.541456Z","shell.execute_reply.started":"2022-07-29T15:11:43.541259Z","shell.execute_reply":"2022-07-29T15:17:37.537826Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# fit the pipeline on the whole training set\npipeline.fit(X_train_subset, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:17:37.543759Z","iopub.execute_input":"2022-07-29T15:17:37.544207Z","iopub.status.idle":"2022-07-29T15:18:05.787273Z","shell.execute_reply.started":"2022-07-29T15:17:37.544124Z","shell.execute_reply":"2022-07-29T15:18:05.785925Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# create a summary table\n# first create a transformed training set through our WoE_Binning custom class\nX_train_woe_transformed = woe_transform.fit_transform(X_train_subset)\n# Store the column names in X_train as a list\nfeature_name = X_train_woe_transformed.columns.values\n# Create a summary table of our logistic regression model\nsummary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n# Create a new column in the dataframe, called 'Coefficients'\nsummary_table['Coefficients'] = np.transpose(pipeline['model'].coef_)\n# Increase the index of every row of the dataframe with 1 to store our model intercept in 1st row\nsummary_table.index = summary_table.index + 1\n# Assign our model intercept to this new row\nsummary_table.loc[0] = ['Intercept', pipeline['model'].intercept_[0]]\n# Sort the dataframe by index\nsummary_table.sort_index(inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:05.788930Z","iopub.execute_input":"2022-07-29T15:18:05.789741Z","iopub.status.idle":"2022-07-29T15:18:06.376524Z","shell.execute_reply.started":"2022-07-29T15:18:05.789695Z","shell.execute_reply":"2022-07-29T15:18:06.374982Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"summary_table","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:06.378473Z","iopub.execute_input":"2022-07-29T15:18:06.379232Z","iopub.status.idle":"2022-07-29T15:18:06.395997Z","shell.execute_reply.started":"2022-07-29T15:18:06.379183Z","shell.execute_reply":"2022-07-29T15:18:06.394646Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"summary_table.sort_values(by=['Coefficients'],ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:06.397484Z","iopub.execute_input":"2022-07-29T15:18:06.398756Z","iopub.status.idle":"2022-07-29T15:18:06.420489Z","shell.execute_reply.started":"2022-07-29T15:18:06.398715Z","shell.execute_reply":"2022-07-29T15:18:06.419091Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"#Prediction Time","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:06.424234Z","iopub.execute_input":"2022-07-29T15:18:06.425097Z","iopub.status.idle":"2022-07-29T15:18:06.430717Z","shell.execute_reply.started":"2022-07-29T15:18:06.425053Z","shell.execute_reply":"2022-07-29T15:18:06.428977Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# make preditions on our test set\ny_hat_test = pipeline.predict(X_test_subset)\n# get the predicted probabilities\ny_hat_test_proba = pipeline.predict_proba(X_test_subset)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:06.432975Z","iopub.execute_input":"2022-07-29T15:18:06.433491Z","iopub.status.idle":"2022-07-29T15:18:07.016663Z","shell.execute_reply.started":"2022-07-29T15:18:06.433410Z","shell.execute_reply":"2022-07-29T15:18:07.015006Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# select the probabilities of only the positive class (class 1 - default) \ny_hat_test_proba = y_hat_test_proba[:][: , 1]","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:07.018678Z","iopub.execute_input":"2022-07-29T15:18:07.019090Z","iopub.status.idle":"2022-07-29T15:18:07.026365Z","shell.execute_reply.started":"2022-07-29T15:18:07.019046Z","shell.execute_reply":"2022-07-29T15:18:07.024943Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# we will now create a new DF with actual classes and the predicted probabilities\n# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\ny_test_temp = y_test.copy()\ny_test_temp.reset_index(drop = True, inplace = True)\ny_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n# Rename the columns\ny_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n# Makes the index of one dataframe equal to the index of another dataframe.\ny_test_proba.index = X_test.index\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:07.028401Z","iopub.execute_input":"2022-07-29T15:18:07.029126Z","iopub.status.idle":"2022-07-29T15:18:07.058282Z","shell.execute_reply.started":"2022-07-29T15:18:07.029083Z","shell.execute_reply":"2022-07-29T15:18:07.056955Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# get the values required to plot a ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n                                 y_test_proba['y_hat_test_proba'])\n# plot the ROC curve\nplt.plot(fpr, tpr)\n# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:07.060363Z","iopub.execute_input":"2022-07-29T15:18:07.061199Z","iopub.status.idle":"2022-07-29T15:18:07.366428Z","shell.execute_reply.started":"2022-07-29T15:18:07.061145Z","shell.execute_reply":"2022-07-29T15:18:07.365182Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\nAUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n# calculate Gini from AUROC\nGini = AUROC * 2 - 1\n# print AUROC and Gini\nprint('AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (Gini))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:07.368110Z","iopub.execute_input":"2022-07-29T15:18:07.368545Z","iopub.status.idle":"2022-07-29T15:18:07.404834Z","shell.execute_reply.started":"2022-07-29T15:18:07.368504Z","shell.execute_reply":"2022-07-29T15:18:07.403477Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# draw a PR curve\n# calculate the no skill line as the proportion of the positive class\nno_skill = len(y_test[y_test == 1]) / len(y)\n# plot the no skill precision-recall curve\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# get the values required to plot a PR curve\nprecision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], \n                                                       y_test_proba['y_hat_test_proba'])\n# plot PR curve\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.title('PR curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:18:07.407973Z","iopub.execute_input":"2022-07-29T15:18:07.408272Z","iopub.status.idle":"2022-07-29T15:18:07.932206Z","shell.execute_reply.started":"2022-07-29T15:18:07.408244Z","shell.execute_reply":"2022-07-29T15:18:07.930956Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"#finding best threshold for logistic regression confusion matrix\nfrom sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n                                 y_test_proba['y_hat_test_proba'])\nauc_logistic = auc(fpr, tpr)\ni = np.arange(len(tpr)) \nroc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\nideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\nprint(\"Ideal logistic threshold is: \", ideal_roc_thresh['thresholds']) ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:21:33.127344Z","iopub.execute_input":"2022-07-29T15:21:33.127770Z","iopub.status.idle":"2022-07-29T15:21:33.161538Z","shell.execute_reply.started":"2022-07-29T15:21:33.127740Z","shell.execute_reply":"2022-07-29T15:21:33.160136Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"y_test_proba['y_hat_test_proba'] = np.where((y_test_proba['y_hat_test_proba'] >= 0.469598), 1, 0)\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:41:45.021757Z","iopub.execute_input":"2022-07-29T15:41:45.022513Z","iopub.status.idle":"2022-07-29T15:41:45.040732Z","shell.execute_reply.started":"2022-07-29T15:41:45.022476Z","shell.execute_reply":"2022-07-29T15:41:45.039191Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"## EXTRA: Confusion Matrix\nfrom sklearn.metrics import accuracy_score\n\ncm = confusion_matrix(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba']) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm, annot=True, fmt='g')\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])) ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:43:10.323326Z","iopub.execute_input":"2022-07-29T15:43:10.323728Z","iopub.status.idle":"2022-07-29T15:43:10.608688Z","shell.execute_reply.started":"2022-07-29T15:43:10.323697Z","shell.execute_reply":"2022-07-29T15:43:10.607437Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"# here i tried to add scaling to see wether it differs or not but i found that it doesnot add value","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:43:18.610549Z","iopub.execute_input":"2022-07-29T15:43:18.610969Z","iopub.status.idle":"2022-07-29T15:43:18.618179Z","shell.execute_reply.started":"2022-07-29T15:43:18.610924Z","shell.execute_reply":"2022-07-29T15:43:18.616611Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# define modeling pipeline\nreg = LogisticRegression(max_iter=5000 , class_weight = 'balanced',C=1,penalty='l2')\nwoe_transform = WoE_Binning(X)\npipeline = Pipeline(steps=[('woe', woe_transform), ('scale', StandardScaler()),('model', reg)])\n\n# define cross-validation criteria\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\n# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\nscores = cross_val_score(pipeline, X_train_subset, y_train, scoring = 'roc_auc', cv = cv)\nAUROC = np.mean(scores)\nGINI = AUROC * 2 - 1\n\n# print the mean AUROC score and Gini\nprint('Mean AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (GINI))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:43:18.745430Z","iopub.execute_input":"2022-07-29T15:43:18.745819Z","iopub.status.idle":"2022-07-29T15:45:21.874835Z","shell.execute_reply.started":"2022-07-29T15:43:18.745789Z","shell.execute_reply":"2022-07-29T15:45:21.873428Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# now i will try another models to see wether they will give me higher accuracy or not and if so i will tune thier parameters","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:45:21.877750Z","iopub.execute_input":"2022-07-29T15:45:21.879209Z","iopub.status.idle":"2022-07-29T15:45:21.886992Z","shell.execute_reply.started":"2022-07-29T15:45:21.879115Z","shell.execute_reply":"2022-07-29T15:45:21.885763Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"# define modeling pipeline\nrf = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n            criterion='gini', max_depth=50,\n            max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=15,\n            min_samples_split=2, min_weight_fraction_leaf=0.0, max_features=25,\n            n_estimators=200, n_jobs=-1, oob_score=False, random_state=42,\n            verbose=0, warm_start=False)\nwoe_transform = WoE_Binning(X)\npipeline = Pipeline(steps=[('woe', woe_transform), ('scale', StandardScaler()),('model', rf)])\n\n# define cross-validation criteria\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\n# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\nscores = cross_val_score(pipeline, X_train_subset, y_train, scoring = 'roc_auc', cv = cv)\nAUROC = np.mean(scores)\nGINI = AUROC * 2 - 1\n\n# print the mean AUROC score and Gini\nprint('Mean AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (GINI))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T15:45:21.888979Z","iopub.execute_input":"2022-07-29T15:45:21.889414Z","iopub.status.idle":"2022-07-29T16:21:52.769547Z","shell.execute_reply.started":"2022-07-29T15:45:21.889368Z","shell.execute_reply":"2022-07-29T16:21:52.767983Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"# define modeling pipeline i use the logistic regression to give me probabilities for credit scoring\n\n# rf = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n#             criterion='gini',\n#             max_leaf_nodes=None, min_impurity_decrease=0.0,\n#             min_weight_fraction_leaf=0.0,\n#             n_jobs=-1, oob_score=False, random_state=42,\n#             verbose=0, warm_start=False)\n# woe_transform = WoE_Binning(X)\n# pipeline = Pipeline(steps=[('woe', woe_transform), ('model', rf)])\n\n# parameters = {'model__max_features': [20,40,60,80], \n#               'model__min_samples_leaf': [5, 7, 9,12], \n#               'model__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n#              'model__min_samples_split': [2, 5, 10],\n#              'model__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]},\n\n# parameters = {'model__n_estimators': [200, 400 , 1000]}\n# # define cross-validation criteria\n# cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=1)\n\n# # fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\n# # define the grid search\n# grid  = GridSearchCV(pipeline, param_grid=parameters, scoring='roc_auc', cv=cv)\n# grid_result = grid.fit(X_train_subset,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:21:52.773774Z","iopub.execute_input":"2022-07-29T16:21:52.774541Z","iopub.status.idle":"2022-07-29T16:21:52.782031Z","shell.execute_reply.started":"2022-07-29T16:21:52.774500Z","shell.execute_reply":"2022-07-29T16:21:52.779884Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"# summarize results\n# print(\"Best Score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# print(\"Best estimator:  %s\" % (grid_result.best_estimator_))\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n# for mean, stdev, param in zip(means,stds,params):\n#      print(\"Mean = %f (std=%f) with: %r\" % (mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:21:52.783962Z","iopub.execute_input":"2022-07-29T16:21:52.785036Z","iopub.status.idle":"2022-07-29T16:21:52.799713Z","shell.execute_reply.started":"2022-07-29T16:21:52.784992Z","shell.execute_reply":"2022-07-29T16:21:52.798318Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"# i also here done hyperparameter tuning and hashed it because it really takes very very very long time","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:21:52.801872Z","iopub.execute_input":"2022-07-29T16:21:52.802985Z","iopub.status.idle":"2022-07-29T16:21:52.810624Z","shell.execute_reply.started":"2022-07-29T16:21:52.802911Z","shell.execute_reply":"2022-07-29T16:21:52.809493Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"# fit the pipeline on the whole training set\npipeline.fit(X_train_subset, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:21:52.813853Z","iopub.execute_input":"2022-07-29T16:21:52.814689Z","iopub.status.idle":"2022-07-29T16:24:36.244844Z","shell.execute_reply.started":"2022-07-29T16:21:52.814624Z","shell.execute_reply":"2022-07-29T16:24:36.243463Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"# create a summary table\n# first create a transformed training set through our WoE_Binning custom class\nX_train_woe_transformed = woe_transform.fit_transform(X_train_subset)\n# Store the column names in X_train as a list\nfeature_name = X_train_woe_transformed.columns.values\n# Create a summary table of our logistic regression model\nsummary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n# Create a new column in the dataframe, called 'Coefficients'\nsummary_table['importances'] = np.transpose(pipeline['model'].feature_importances_)\n# Sort the dataframe by index\nsummary_table.sort_index(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:36.247094Z","iopub.execute_input":"2022-07-29T16:24:36.247537Z","iopub.status.idle":"2022-07-29T16:24:36.888773Z","shell.execute_reply.started":"2022-07-29T16:24:36.247490Z","shell.execute_reply":"2022-07-29T16:24:36.887479Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"summary_table","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:36.892869Z","iopub.execute_input":"2022-07-29T16:24:36.893224Z","iopub.status.idle":"2022-07-29T16:24:36.909956Z","shell.execute_reply.started":"2022-07-29T16:24:36.893180Z","shell.execute_reply":"2022-07-29T16:24:36.908049Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# make preditions on our test set\ny_hat_test_proba = pipeline.predict(X_test_subset)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:36.917718Z","iopub.execute_input":"2022-07-29T16:24:36.918163Z","iopub.status.idle":"2022-07-29T16:24:40.036978Z","shell.execute_reply.started":"2022-07-29T16:24:36.918110Z","shell.execute_reply":"2022-07-29T16:24:40.035533Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# we will now create a new DF with actual classes and the predicted probabilities\n# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\ny_test_temp = y_test.copy()\ny_test_temp.reset_index(drop = True, inplace = True)\ny_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n# Rename the columns\ny_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n# Makes the index of one dataframe equal to the index of another dataframe.\ny_test_proba.index = X_test.index\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:40.039110Z","iopub.execute_input":"2022-07-29T16:24:40.039630Z","iopub.status.idle":"2022-07-29T16:24:40.061560Z","shell.execute_reply.started":"2022-07-29T16:24:40.039589Z","shell.execute_reply":"2022-07-29T16:24:40.060381Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# get the values required to plot a ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n                                 y_test_proba['y_hat_test_proba'])\n# plot the ROC curve\nplt.plot(fpr, tpr)\n# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:40.062877Z","iopub.execute_input":"2022-07-29T16:24:40.063807Z","iopub.status.idle":"2022-07-29T16:24:40.337434Z","shell.execute_reply.started":"2022-07-29T16:24:40.063750Z","shell.execute_reply":"2022-07-29T16:24:40.336045Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\nAUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n# calculate Gini from AUROC\nGini = AUROC * 2 - 1\n# print AUROC and Gini\nprint('AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (Gini))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:40.340897Z","iopub.execute_input":"2022-07-29T16:24:40.341279Z","iopub.status.idle":"2022-07-29T16:24:40.366616Z","shell.execute_reply.started":"2022-07-29T16:24:40.341251Z","shell.execute_reply":"2022-07-29T16:24:40.365376Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# draw a PR curve\n# calculate the no skill line as the proportion of the positive class\nno_skill = len(y_test[y_test == 1]) / len(y)\n# plot the no skill precision-recall curve\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# get the values required to plot a PR curve\nprecision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], \n                                                       y_test_proba['y_hat_test_proba'])\n# plot PR curve\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.title('PR curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:40.367869Z","iopub.execute_input":"2022-07-29T16:24:40.368800Z","iopub.status.idle":"2022-07-29T16:24:40.651588Z","shell.execute_reply.started":"2022-07-29T16:24:40.368760Z","shell.execute_reply":"2022-07-29T16:24:40.649967Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"# so logistic regression is better than random forest in prediction","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:40.654348Z","iopub.execute_input":"2022-07-29T16:24:40.655164Z","iopub.status.idle":"2022-07-29T16:24:40.661127Z","shell.execute_reply.started":"2022-07-29T16:24:40.655104Z","shell.execute_reply":"2022-07-29T16:24:40.659863Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"xgbclf = XGBClassifier(random_state=123,use_label_encoder=False)\nwoe_transform = WoE_Binning(X)\npipeline = Pipeline(steps=[('woe', woe_transform), ('scale', StandardScaler()),('model', xgbclf)])\n\n# define cross-validation criteria\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\n# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\nscores = cross_val_score(pipeline, X_train_subset, y_train, scoring = 'roc_auc', cv = cv)\nAUROC = np.mean(scores)\nGINI = AUROC * 2 - 1\n\n# print the mean AUROC score and Gini\nprint('Mean AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (GINI))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:24:40.663017Z","iopub.execute_input":"2022-07-29T16:24:40.663638Z","iopub.status.idle":"2022-07-29T16:50:28.840504Z","shell.execute_reply.started":"2022-07-29T16:24:40.663582Z","shell.execute_reply":"2022-07-29T16:50:28.839114Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"# fit the pipeline on the whole training set\npipeline.fit(X_train_subset, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:50:28.842974Z","iopub.execute_input":"2022-07-29T16:50:28.844094Z","iopub.status.idle":"2022-07-29T16:52:36.846222Z","shell.execute_reply.started":"2022-07-29T16:50:28.844048Z","shell.execute_reply":"2022-07-29T16:52:36.844926Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# create a summary table\n# first create a transformed training set through our WoE_Binning custom class\nX_train_woe_transformed = woe_transform.fit_transform(X_train_subset)\n# Store the column names in X_train as a list\nfeature_name = X_train_woe_transformed.columns.values\n# Create a summary table of our logistic regression model\nsummary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n# Create a new column in the dataframe, called 'Coefficients'\nsummary_table['importances'] = np.transpose(pipeline['model'].feature_importances_)\n# Sort the dataframe by index\nsummary_table.sort_index(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:36.849272Z","iopub.execute_input":"2022-07-29T16:52:36.850117Z","iopub.status.idle":"2022-07-29T16:52:37.440132Z","shell.execute_reply.started":"2022-07-29T16:52:36.850076Z","shell.execute_reply":"2022-07-29T16:52:37.438748Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"summary_table","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:37.443350Z","iopub.execute_input":"2022-07-29T16:52:37.443800Z","iopub.status.idle":"2022-07-29T16:52:37.459318Z","shell.execute_reply.started":"2022-07-29T16:52:37.443756Z","shell.execute_reply":"2022-07-29T16:52:37.457925Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"# make preditions on our test set\ny_hat_test_proba = pipeline.predict(X_test_subset)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:37.461001Z","iopub.execute_input":"2022-07-29T16:52:37.461555Z","iopub.status.idle":"2022-07-29T16:52:37.993648Z","shell.execute_reply.started":"2022-07-29T16:52:37.461511Z","shell.execute_reply":"2022-07-29T16:52:37.992426Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"# we will now create a new DF with actual classes and the predicted probabilities\n# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\ny_test_temp = y_test.copy()\ny_test_temp.reset_index(drop = True, inplace = True)\ny_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n# Rename the columns\ny_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n# Makes the index of one dataframe equal to the index of another dataframe.\ny_test_proba.index = X_test.index\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:37.995704Z","iopub.execute_input":"2022-07-29T16:52:37.996183Z","iopub.status.idle":"2022-07-29T16:52:38.019433Z","shell.execute_reply.started":"2022-07-29T16:52:37.996121Z","shell.execute_reply":"2022-07-29T16:52:38.018249Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# get the values required to plot a ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n                                 y_test_proba['y_hat_test_proba'])\n# plot the ROC curve\nplt.plot(fpr, tpr)\n# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.021260Z","iopub.execute_input":"2022-07-29T16:52:38.021794Z","iopub.status.idle":"2022-07-29T16:52:38.295954Z","shell.execute_reply.started":"2022-07-29T16:52:38.021734Z","shell.execute_reply":"2022-07-29T16:52:38.294774Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\nAUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n# calculate Gini from AUROC\nGini = AUROC * 2 - 1\n# print AUROC and Gini\nprint('AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (Gini))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.297384Z","iopub.execute_input":"2022-07-29T16:52:38.297787Z","iopub.status.idle":"2022-07-29T16:52:38.322837Z","shell.execute_reply.started":"2022-07-29T16:52:38.297738Z","shell.execute_reply":"2022-07-29T16:52:38.321314Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"# draw a PR curve\n# calculate the no skill line as the proportion of the positive class\nno_skill = len(y_test[y_test == 1]) / len(y)\n# plot the no skill precision-recall curve\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# get the values required to plot a PR curve\nprecision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], \n                                                       y_test_proba['y_hat_test_proba'])\n# plot PR curve\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.title('PR curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.324620Z","iopub.execute_input":"2022-07-29T16:52:38.325069Z","iopub.status.idle":"2022-07-29T16:52:38.605993Z","shell.execute_reply.started":"2022-07-29T16:52:38.325032Z","shell.execute_reply":"2022-07-29T16:52:38.604937Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"#also logistic regression is better than xgboost","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.607789Z","iopub.execute_input":"2022-07-29T16:52:38.608345Z","iopub.status.idle":"2022-07-29T16:52:38.614554Z","shell.execute_reply.started":"2022-07-29T16:52:38.608287Z","shell.execute_reply":"2022-07-29T16:52:38.612990Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"# try WOE binning without dropping the reference categories columns","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.616851Z","iopub.execute_input":"2022-07-29T16:52:38.617840Z","iopub.status.idle":"2022-07-29T16:52:38.625472Z","shell.execute_reply.started":"2022-07-29T16:52:38.617796Z","shell.execute_reply":"2022-07-29T16:52:38.624180Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# custom transformer class to create new categorical dummy features\nclass WoE_Binning(BaseEstimator, TransformerMixin):\n    def __init__(self, X): # no *args or *kargs\n        self.X = X\n    def fit(self, X, y = None):\n        return self #nothing else to do\n    def transform(self, X):\n        X_new = X.loc[:, 'grade:A': 'grade:G']\n        X_new['home_ownership:OWN'] = X.loc[:,'home_ownership:OWN']\n        X_new['home_ownership:MORTGAGE'] = X.loc[:,'home_ownership:MORTGAGE']\n        X_new['home_ownership:OTHER_NONE_RENT'] = sum([X['home_ownership:OTHER'], X['home_ownership:NONE'], X['home_ownership:RENT']])\n        X_new = pd.concat([X_new, X.loc[:, 'verification_status:Not Verified':'verification_status:Verified']], axis = 1)\n        X_new['purpose:debt_consolidation'] = X.loc[:,'purpose:debt_consolidation']\n        X_new['purpose:credit_card'] = X.loc[:,'purpose:credit_card']\n        X_new['purpose:major_purch__car__home_impr'] = sum([X['purpose:major_purchase'], X['purpose:car'], X['purpose:home_improvement']])\n        X_new['purpose:educ__ren_en__sm_b__mov'] = sum([X['purpose:educational'], X['purpose:renewable_energy'], X['purpose:small_business'], \n                                                        X['purpose:moving']])\n        X_new['purpose:vacation__house__wedding__med__oth'] = sum([X['purpose:vacation'], X['purpose:house'], X['purpose:wedding'], \n                                                                   X['purpose:medical'], X['purpose:other']])\n        X_new['term:36'] = np.where((X['term'] == 36), 1, 0)\n        X_new['term:60'] = np.where((X['term'] == 60), 1, 0)\n        X_new['int_rate:<7.071'] = np.where((X['int_rate'] <= 7.071), 1, 0)\n        X_new['int_rate:7.071-10.374'] = np.where((X['int_rate'] > 7.071) & (X['int_rate'] <= 10.374), 1, 0)\n        X_new['int_rate:10.374-13.676'] = np.where((X['int_rate'] > 10.374) & (X['int_rate'] <= 13.676), 1, 0)\n        X_new['int_rate:13.676-15.74'] = np.where((X['int_rate'] > 13.676) & (X['int_rate'] <= 15.74), 1, 0)\n        X_new['int_rate:15.74-20.281'] = np.where((X['int_rate'] > 15.74) & (X['int_rate'] <= 20.281), 1, 0)\n        X_new['int_rate:>20.281'] = np.where((X['int_rate'] > 20.281), 1, 0)\n        X_new['annual_inc:missing'] = np.where(X['annual_inc'].isnull(), 1, 0)\n        X_new['annual_inc:<28,555'] = np.where((X['annual_inc'] <= 28555), 1, 0)\n        X_new['annual_inc:28,555-37,440'] = np.where((X['annual_inc'] > 28555) & (X['annual_inc'] <= 37440), 1, 0)\n        X_new['annual_inc:37,440-61,137'] = np.where((X['annual_inc'] > 37440) & (X['annual_inc'] <= 61137), 1, 0)\n        X_new['annual_inc:61,137-81,872'] = np.where((X['annual_inc'] > 61137) & (X['annual_inc'] <= 81872), 1, 0)\n        X_new['annual_inc:81,872-102,606'] = np.where((X['annual_inc'] > 81872) & (X['annual_inc'] <= 102606), 1, 0)\n        X_new['annual_inc:102,606-120,379'] = np.where((X['annual_inc'] > 102606) & (X['annual_inc'] <= 120379), 1, 0)\n        X_new['annual_inc:120,379-150,000'] = np.where((X['annual_inc'] > 120379) & (X['annual_inc'] <= 150000), 1, 0)\n        X_new['annual_inc:>150K'] = np.where((X['annual_inc'] > 150000), 1, 0)\n        X_new['dti:<=1.6'] = np.where((X['dti'] <= 1.6), 1, 0)\n        X_new['dti:1.6-5.599'] = np.where((X['dti'] > 1.6) & (X['dti'] <= 5.599), 1, 0)\n        X_new['dti:5.599-10.397'] = np.where((X['dti'] > 5.599) & (X['dti'] <= 10.397), 1, 0)\n        X_new['dti:10.397-15.196'] = np.where((X['dti'] > 10.397) & (X['dti'] <= 15.196), 1, 0)\n        X_new['dti:15.196-19.195'] = np.where((X['dti'] > 15.196) & (X['dti'] <= 19.195), 1, 0)\n        X_new['dti:19.195-24.794'] = np.where((X['dti'] > 19.195) & (X['dti'] <= 24.794), 1, 0)\n        X_new['dti:24.794-35.191'] = np.where((X['dti'] > 24.794) & (X['dti'] <= 35.191), 1, 0)\n        X_new['dti:>35.191'] = np.where((X['dti'] > 35.191), 1, 0)\n        X_new['inq_last_6mths:missing'] = np.where(X['inq_last_6mths'].isnull(), 1, 0)\n        X_new['inq_last_6mths:0'] = np.where((X['inq_last_6mths'] == 0), 1, 0)\n        X_new['inq_last_6mths:1-2'] = np.where((X['inq_last_6mths'] >= 1) & (X['inq_last_6mths'] <= 2), 1, 0)\n        X_new['inq_last_6mths:3-4'] = np.where((X['inq_last_6mths'] >= 3) & (X['inq_last_6mths'] <= 4), 1, 0)\n        X_new['inq_last_6mths:>4'] = np.where((X['inq_last_6mths'] > 4), 1, 0)\n        X_new['revol_util:missing'] = np.where(X['revol_util'].isnull(), 1, 0)\n        X_new['revol_util:<0.1'] = np.where((X['revol_util'] <= 0.1), 1, 0)\n        X_new['revol_util:0.1-0.2'] = np.where((X['revol_util'] > 0.1) & (X['revol_util'] <= 0.2), 1, 0)\n        X_new['revol_util:0.2-0.3'] = np.where((X['revol_util'] > 0.2) & (X['revol_util'] <= 0.3), 1, 0)\n        X_new['revol_util:0.3-0.4'] = np.where((X['revol_util'] > 0.3) & (X['revol_util'] <= 0.4), 1, 0)\n        X_new['revol_util:0.4-0.5'] = np.where((X['revol_util'] > 0.4) & (X['revol_util'] <= 0.5), 1, 0)\n        X_new['revol_util:0.5-0.6'] = np.where((X['revol_util'] > 0.5) & (X['revol_util'] <= 0.6), 1, 0)\n        X_new['revol_util:0.6-0.7'] = np.where((X['revol_util'] > 0.6) & (X['revol_util'] <= 0.7), 1, 0)\n        X_new['revol_util:0.7-0.8'] = np.where((X['revol_util'] > 0.7) & (X['revol_util'] <= 0.8), 1, 0)\n        X_new['revol_util:0.8-0.9'] = np.where((X['revol_util'] > 0.8) & (X['revol_util'] <= 0.9), 1, 0)\n        X_new['revol_util:0.9-1.0'] = np.where((X['revol_util'] > 0.9) & (X['revol_util'] <= 1.0), 1, 0)\n        X_new['revol_util:>1.0'] = np.where((X['revol_util'] > 1.0), 1, 0)\n        X_new['out_prncp:<1,286'] = np.where((X['out_prncp'] <= 1286), 1, 0)\n        X_new['out_prncp:1,286-6,432'] = np.where((X['out_prncp'] > 1286) & (X['out_prncp'] <= 6432), 1, 0)\n        X_new['out_prncp:6,432-9,005'] = np.where((X['out_prncp'] > 6432) & (X['out_prncp'] <= 9005), 1, 0)\n        X_new['out_prncp:9,005-10,291'] = np.where((X['out_prncp'] > 9005) & (X['out_prncp'] <= 10291), 1, 0)\n        X_new['out_prncp:10,291-15,437'] = np.where((X['out_prncp'] > 10291) & (X['out_prncp'] <= 15437), 1, 0)\n        X_new['out_prncp:>15,437'] = np.where((X['out_prncp'] > 15437), 1, 0)\n        X_new['total_pymnt:<10,000'] = np.where((X['total_pymnt'] <= 10000), 1, 0)\n        X_new['total_pymnt:10,000-15,000'] = np.where((X['total_pymnt'] > 10000) & (X['total_pymnt'] <= 15000), 1, 0)\n        X_new['total_pymnt:15,000-20,000'] = np.where((X['total_pymnt'] > 15000) & (X['total_pymnt'] <= 20000), 1, 0)\n        X_new['total_pymnt:20,000-25,000'] = np.where((X['total_pymnt'] > 20000) & (X['total_pymnt'] <= 25000), 1, 0)\n        X_new['total_pymnt:>25,000'] = np.where((X['total_pymnt'] > 25000), 1, 0)\n        X_new['total_rec_int:<1,089'] = np.where((X['total_rec_int'] <= 1089), 1, 0)\n        X_new['total_rec_int:1,089-2,541'] = np.where((X['total_rec_int'] > 1089) & (X['total_rec_int'] <= 2541), 1, 0)\n        X_new['total_rec_int:2,541-4,719'] = np.where((X['total_rec_int'] > 2541) & (X['total_rec_int'] <= 4719), 1, 0)\n        X_new['total_rec_int:4,719-7,260'] = np.where((X['total_rec_int'] > 4719) & (X['total_rec_int'] <= 7260), 1, 0)\n        X_new['total_rec_int:>7,260'] = np.where((X['total_rec_int'] > 7260), 1, 0)\n        X_new['total_rev_hi_lim:missing'] = np.where(X['total_rev_hi_lim'].isnull(), 1, 0)\n        X_new['total_rev_hi_lim:<6,381'] = np.where((X['total_rev_hi_lim'] <= 6381), 1, 0)\n        X_new['total_rev_hi_lim:6,381-19,144'] = np.where((X['total_rev_hi_lim'] > 6381) & (X['total_rev_hi_lim'] <= 19144), 1, 0)\n        X_new['total_rev_hi_lim:19,144-25,525'] = np.where((X['total_rev_hi_lim'] > 19144) & (X['total_rev_hi_lim'] <= 25525), 1, 0)\n        X_new['total_rev_hi_lim:25,525-35,097'] = np.where((X['total_rev_hi_lim'] > 25525) & (X['total_rev_hi_lim'] <= 35097), 1, 0)\n        X_new['total_rev_hi_lim:35,097-54,241'] = np.where((X['total_rev_hi_lim'] > 35097) & (X['total_rev_hi_lim'] <= 54241), 1, 0)\n        X_new['total_rev_hi_lim:54,241-79,780'] = np.where((X['total_rev_hi_lim'] > 54241) & (X['total_rev_hi_lim'] <= 79780), 1, 0)\n        X_new['total_rev_hi_lim:>79,780'] = np.where((X['total_rev_hi_lim'] > 79780), 1, 0)\n        X_new['mths_since_earliest_cr_line:missing'] = np.where(X['mths_since_earliest_cr_line'].isnull(), 1, 0)\n        X_new['mths_since_earliest_cr_line:<125'] = np.where((X['mths_since_earliest_cr_line'] <= 125), 1, 0)\n        X_new['mths_since_earliest_cr_line:125-167'] = np.where((X['mths_since_earliest_cr_line'] > 125) & (X['mths_since_earliest_cr_line'] <= 167), 1, 0)\n        X_new['mths_since_earliest_cr_line:167-249'] = np.where((X['mths_since_earliest_cr_line'] > 167) & (X['mths_since_earliest_cr_line'] <= 249), 1, 0)\n        X_new['mths_since_earliest_cr_line:249-331'] = np.where((X['mths_since_earliest_cr_line'] > 249) & (X['mths_since_earliest_cr_line'] <= 331), 1, 0)\n        X_new['mths_since_earliest_cr_line:331-434'] = np.where((X['mths_since_earliest_cr_line'] > 331) & (X['mths_since_earliest_cr_line'] <= 434), 1, 0)\n        X_new['mths_since_earliest_cr_line:>434'] = np.where((X['mths_since_earliest_cr_line'] > 434), 1, 0)\n        X_new['mths_since_issue_d:<79'] = np.where((X['mths_since_issue_d'] <= 79), 1, 0)\n        X_new['mths_since_issue_d:79-89'] = np.where((X['mths_since_issue_d'] > 79) & (X['mths_since_issue_d'] <= 89), 1, 0)\n        X_new['mths_since_issue_d:89-100'] = np.where((X['mths_since_issue_d'] > 89) & (X['mths_since_issue_d'] <= 100), 1, 0)\n        X_new['mths_since_issue_d:100-122'] = np.where((X['mths_since_issue_d'] > 100) & (X['mths_since_issue_d'] <= 122), 1, 0)\n        X_new['mths_since_issue_d:>122'] = np.where((X['mths_since_issue_d'] > 122), 1, 0)\n        X_new['mths_since_last_credit_pull_d:missing'] = np.where(X['mths_since_last_credit_pull_d'].isnull(), 1, 0)\n        X_new['mths_since_last_credit_pull_d:<56'] = np.where((X['mths_since_last_credit_pull_d'] <= 56), 1, 0)\n        X_new['mths_since_last_credit_pull_d:56-61'] = np.where((X['mths_since_last_credit_pull_d'] > 56) & (X['mths_since_last_credit_pull_d'] <= 61), 1, 0)\n        X_new['mths_since_last_credit_pull_d:61-75'] = np.where((X['mths_since_last_credit_pull_d'] > 61) & (X['mths_since_last_credit_pull_d'] <= 75), 1, 0)\n        X_new['mths_since_last_credit_pull_d:>75'] = np.where((X['mths_since_last_credit_pull_d'] > 75), 1, 0)\n        return X_new","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.627827Z","iopub.execute_input":"2022-07-29T16:52:38.628430Z","iopub.status.idle":"2022-07-29T16:52:38.693784Z","shell.execute_reply.started":"2022-07-29T16:52:38.628386Z","shell.execute_reply":"2022-07-29T16:52:38.692399Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"# define modeling pipeline\nreg = LogisticRegression(max_iter=5000 , class_weight = 'balanced',C=1,penalty='l2')\nwoe_transform = WoE_Binning(X)\npipeline = Pipeline(steps=[('woe', woe_transform), ('model', reg)])\n\n# define cross-validation criteria\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\n# fit and evaluate the logistic regression pipeline with cross-validation as defined in cv\nscores = cross_val_score(pipeline, X_train_subset, y_train, scoring = 'roc_auc', cv = cv)\nAUROC = np.mean(scores)\nGINI = AUROC * 2 - 1\n\n# print the mean AUROC score and Gini\nprint('Mean AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (GINI))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:52:38.705009Z","iopub.execute_input":"2022-07-29T16:52:38.705430Z","iopub.status.idle":"2022-07-29T16:58:56.379701Z","shell.execute_reply.started":"2022-07-29T16:52:38.705385Z","shell.execute_reply":"2022-07-29T16:58:56.378330Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"# fit the pipeline on the whole training set\npipeline.fit(X_train_subset, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:58:56.381350Z","iopub.execute_input":"2022-07-29T16:58:56.382481Z","iopub.status.idle":"2022-07-29T16:59:34.094435Z","shell.execute_reply.started":"2022-07-29T16:58:56.382421Z","shell.execute_reply":"2022-07-29T16:59:34.092939Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# create a summary table\n# first create a transformed training set through our WoE_Binning custom class\nX_train_woe_transformed = woe_transform.fit_transform(X_train_subset)\n# Store the column names in X_train as a list\nfeature_name = X_train_woe_transformed.columns.values\n# Create a summary table of our logistic regression model\nsummary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n# Create a new column in the dataframe, called 'Coefficients'\nsummary_table['Coefficients'] = np.transpose(pipeline['model'].coef_)\n# Increase the index of every row of the dataframe with 1 to store our model intercept in 1st row\nsummary_table.index = summary_table.index + 1\n# Assign our model intercept to this new row\nsummary_table.loc[0] = ['Intercept', pipeline['model'].intercept_[0]]\n# Sort the dataframe by index\nsummary_table.sort_index(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:34.097436Z","iopub.execute_input":"2022-07-29T16:59:34.098160Z","iopub.status.idle":"2022-07-29T16:59:34.335515Z","shell.execute_reply.started":"2022-07-29T16:59:34.098114Z","shell.execute_reply":"2022-07-29T16:59:34.334214Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"summary_table","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:34.338333Z","iopub.execute_input":"2022-07-29T16:59:34.339545Z","iopub.status.idle":"2022-07-29T16:59:34.355765Z","shell.execute_reply.started":"2022-07-29T16:59:34.339481Z","shell.execute_reply":"2022-07-29T16:59:34.354218Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"summary_table.sort_values(by=['Coefficients'],ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:34.357789Z","iopub.execute_input":"2022-07-29T16:59:34.358305Z","iopub.status.idle":"2022-07-29T16:59:34.382520Z","shell.execute_reply.started":"2022-07-29T16:59:34.358262Z","shell.execute_reply":"2022-07-29T16:59:34.379507Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"# make preditions on our test set\ny_hat_test = pipeline.predict(X_test_subset)\n# get the predicted probabilities\ny_hat_test_proba = pipeline.predict_proba(X_test_subset)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:34.384899Z","iopub.execute_input":"2022-07-29T16:59:34.392187Z","iopub.status.idle":"2022-07-29T16:59:34.971111Z","shell.execute_reply.started":"2022-07-29T16:59:34.392141Z","shell.execute_reply":"2022-07-29T16:59:34.969385Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"# select the probabilities of only the positive class (class 1 - default) \ny_hat_test_proba = y_hat_test_proba[:][: , 1]","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:34.972874Z","iopub.execute_input":"2022-07-29T16:59:34.973336Z","iopub.status.idle":"2022-07-29T16:59:34.985972Z","shell.execute_reply.started":"2022-07-29T16:59:34.973291Z","shell.execute_reply":"2022-07-29T16:59:34.984495Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"# we will now create a new DF with actual classes and the predicted probabilities\n# create a temp y_test DF to reset its index to allow proper concaternation with y_hat_test_proba\ny_test_temp = y_test.copy()\ny_test_temp.reset_index(drop = True, inplace = True)\ny_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n# Rename the columns\ny_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n# Makes the index of one dataframe equal to the index of another dataframe.\ny_test_proba.index = X_test.index\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:34.992473Z","iopub.execute_input":"2022-07-29T16:59:34.993395Z","iopub.status.idle":"2022-07-29T16:59:35.027870Z","shell.execute_reply.started":"2022-07-29T16:59:34.993330Z","shell.execute_reply":"2022-07-29T16:59:35.026590Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"# get the values required to plot a ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n                                 y_test_proba['y_hat_test_proba'])\n# plot the ROC curve\nplt.plot(fpr, tpr)\n# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.029314Z","iopub.execute_input":"2022-07-29T16:59:35.030072Z","iopub.status.idle":"2022-07-29T16:59:35.339307Z","shell.execute_reply.started":"2022-07-29T16:59:35.030028Z","shell.execute_reply":"2022-07-29T16:59:35.337972Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\nAUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n# calculate Gini from AUROC\nGini = AUROC * 2 - 1\n# print AUROC and Gini\nprint('AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (Gini))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.341326Z","iopub.execute_input":"2022-07-29T16:59:35.342557Z","iopub.status.idle":"2022-07-29T16:59:35.379358Z","shell.execute_reply.started":"2022-07-29T16:59:35.342485Z","shell.execute_reply":"2022-07-29T16:59:35.377872Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"# draw a PR curve\n# calculate the no skill line as the proportion of the positive class\nno_skill = len(y_test[y_test == 1]) / len(y)\n# plot the no skill precision-recall curve\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# get the values required to plot a PR curve\nprecision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], \n                                                       y_test_proba['y_hat_test_proba'])\n# plot PR curve\nplt.plot(recall, precision, marker='.', label='Logistic')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.title('PR curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.381291Z","iopub.execute_input":"2022-07-29T16:59:35.381737Z","iopub.status.idle":"2022-07-29T16:59:35.908439Z","shell.execute_reply.started":"2022-07-29T16:59:35.381696Z","shell.execute_reply":"2022-07-29T16:59:35.906980Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"# so no difference in numbers but more computation due to more features so i think removing them is better","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.911066Z","iopub.execute_input":"2022-07-29T16:59:35.913109Z","iopub.status.idle":"2022-07-29T16:59:35.918857Z","shell.execute_reply.started":"2022-07-29T16:59:35.913060Z","shell.execute_reply":"2022-07-29T16:59:35.917417Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"# now i will try some different feature selection to see wether the automatic model coding agree with my view of feature selection or not\n# and wether it may give me higher accuracy or not","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.921670Z","iopub.execute_input":"2022-07-29T16:59:35.922467Z","iopub.status.idle":"2022-07-29T16:59:35.931126Z","shell.execute_reply.started":"2022-07-29T16:59:35.922405Z","shell.execute_reply":"2022-07-29T16:59:35.929883Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.934287Z","iopub.execute_input":"2022-07-29T16:59:35.934707Z","iopub.status.idle":"2022-07-29T16:59:35.948252Z","shell.execute_reply.started":"2022-07-29T16:59:35.934666Z","shell.execute_reply":"2022-07-29T16:59:35.947066Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"X_train_cat.columns.values","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.950662Z","iopub.execute_input":"2022-07-29T16:59:35.951646Z","iopub.status.idle":"2022-07-29T16:59:35.962520Z","shell.execute_reply.started":"2022-07-29T16:59:35.951589Z","shell.execute_reply":"2022-07-29T16:59:35.961153Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"# function to create dummy variables\ndef dummy_creation_pure(df, columns_list):\n    df_dummies = []\n    for col in columns_list:\n        df_dummies.append(pd.get_dummies(df[col], prefix = col, prefix_sep = ':'))\n    df_dummies = pd.concat(df_dummies, axis = 1)\n    new_df = df.drop(columns = columns_list)\n    new_df = pd.concat([new_df, df_dummies], axis = 1)\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.964442Z","iopub.execute_input":"2022-07-29T16:59:35.968387Z","iopub.status.idle":"2022-07-29T16:59:35.977431Z","shell.execute_reply.started":"2022-07-29T16:59:35.968344Z","shell.execute_reply":"2022-07-29T16:59:35.976094Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"# apply to our final four categorical variables\nX_train_total = dummy_creation_pure(X_train, X_train_cat.columns.values)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:35.979786Z","iopub.execute_input":"2022-07-29T16:59:35.980787Z","iopub.status.idle":"2022-07-29T16:59:36.449975Z","shell.execute_reply.started":"2022-07-29T16:59:35.980710Z","shell.execute_reply":"2022-07-29T16:59:36.448682Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"X_train_total","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:36.453332Z","iopub.execute_input":"2022-07-29T16:59:36.454140Z","iopub.status.idle":"2022-07-29T16:59:36.537093Z","shell.execute_reply.started":"2022-07-29T16:59:36.454094Z","shell.execute_reply":"2022-07-29T16:59:36.535933Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"# create a pipeline of a specific algorithm with different no. of features to be evaluated\n# models = {}\n# for i in range (18, 28): # loop over a number of features to be used in RFE\n#     FS = RFE(estimator=LogisticRegression(max_iter=5000 , class_weight = 'balanced'), n_features_to_select = i)\n#     LR = LogisticRegression(max_iter=5000 , class_weight = 'balanced')\n#     models[str(i)] = Pipeline(steps = [('features', FS), ('LR model', LR)])\n\n# # evaluate all the models using CV\n# results = []\n# names = []\n\n# for name, model in models.items():\n#     cv = RepeatedStratifiedKFold(n_splits = 3, n_repeats = 1, random_state = 1)\n#     scores = cross_val_score(model, X_train_total, y_train, scoring = 'roc_auc', cv = cv, n_jobs = -1)\n#     results.append(scores)\n#     names.append(name)\n#     print('>%s: %.3f' % (name, np.mean(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:36.539105Z","iopub.execute_input":"2022-07-29T16:59:36.539580Z","iopub.status.idle":"2022-07-29T16:59:36.546666Z","shell.execute_reply.started":"2022-07-29T16:59:36.539538Z","shell.execute_reply":"2022-07-29T16:59:36.544991Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"X_train_total.fillna(X_train_total.mean(), inplace = True)\nsc_X = StandardScaler()\nscaled_X_train_total = sc_X.fit_transform(X_train_total)\nscaled_X_train_total = pd.DataFrame(scaled_X_train_total,columns=[X_train_total.columns.values])\nscaled_X_train_total","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:36.548431Z","iopub.execute_input":"2022-07-29T16:59:36.548964Z","iopub.status.idle":"2022-07-29T16:59:37.783578Z","shell.execute_reply.started":"2022-07-29T16:59:36.548923Z","shell.execute_reply":"2022-07-29T16:59:37.782108Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"scaled_X_train_total.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:37.785368Z","iopub.execute_input":"2022-07-29T16:59:37.786566Z","iopub.status.idle":"2022-07-29T16:59:37.798059Z","shell.execute_reply.started":"2022-07-29T16:59:37.786521Z","shell.execute_reply":"2022-07-29T16:59:37.796708Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nrfe = RFE(estimator=LogisticRegression(max_iter=5000 , class_weight = 'balanced',random_state=0), n_features_to_select=40)\nrfe = rfe.fit(scaled_X_train_total, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T16:59:37.799729Z","iopub.execute_input":"2022-07-29T16:59:37.801042Z","iopub.status.idle":"2022-07-29T18:05:33.198284Z","shell.execute_reply.started":"2022-07-29T16:59:37.800950Z","shell.execute_reply":"2022-07-29T18:05:33.196890Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"print(rfe.support_)\nprint(rfe.ranking_)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T18:05:33.199916Z","iopub.execute_input":"2022-07-29T18:05:33.200666Z","iopub.status.idle":"2022-07-29T18:05:33.212814Z","shell.execute_reply.started":"2022-07-29T18:05:33.200602Z","shell.execute_reply":"2022-07-29T18:05:33.211313Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"rfe.score(scaled_X_train_total, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T18:05:33.215206Z","iopub.execute_input":"2022-07-29T18:05:33.215743Z","iopub.status.idle":"2022-07-29T18:05:33.485715Z","shell.execute_reply.started":"2022-07-29T18:05:33.215703Z","shell.execute_reply":"2022-07-29T18:05:33.483320Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"from operator import itemgetter\nfeatures = X_train_total.columns.to_list()\nfor x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n    print(x, y)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T18:05:33.487259Z","iopub.execute_input":"2022-07-29T18:05:33.487960Z","iopub.status.idle":"2022-07-29T18:05:33.506419Z","shell.execute_reply.started":"2022-07-29T18:05:33.487900Z","shell.execute_reply":"2022-07-29T18:05:33.505071Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"# it seems that the features automatically choosen are nearly close to the features we choose\n# now lets fit the model on them\nreg = LogisticRegression(max_iter=5000 , class_weight = 'balanced',C=1,penalty='l2')\nreg.fit(X_train_total[X_train_total.columns[rfe.support_]], y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:29:02.402081Z","iopub.execute_input":"2022-07-29T19:29:02.403103Z","iopub.status.idle":"2022-07-29T19:34:47.444548Z","shell.execute_reply.started":"2022-07-29T19:29:02.403074Z","shell.execute_reply":"2022-07-29T19:34:47.440896Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"# apply to our final four categorical variables\nX_test_total = dummy_creation_pure(X_test, X_train_cat.columns.values)\nX_test_total.fillna(X_test_total.mean(), inplace = True)\n# reindex the dummied test set variables to make sure all the feature columns in the training set are also available in the test set\nX_test_total = X_test_total.reindex(labels=X_train_total.columns, axis=1, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:38:07.161414Z","iopub.execute_input":"2022-07-29T19:38:07.162127Z","iopub.status.idle":"2022-07-29T19:38:07.362552Z","shell.execute_reply.started":"2022-07-29T19:38:07.162085Z","shell.execute_reply":"2022-07-29T19:38:07.361293Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"X_test_total","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:38:33.437078Z","iopub.execute_input":"2022-07-29T19:38:33.437523Z","iopub.status.idle":"2022-07-29T19:38:33.487231Z","shell.execute_reply.started":"2022-07-29T19:38:33.437494Z","shell.execute_reply":"2022-07-29T19:38:33.485943Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"# choose the 40 columns and visualize them\n# i here make them 40 columns as above we took 18 for numerical features and 4 for categorical features before dummying them so i leave\n# the model itself to choose nearly 40 features out of 118 but if i have higher computational power i would have looped over all of them and\n# by using crossvalscore i will choose the best feature number\nX_test_total[X_train_total.columns[rfe.support_]]","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:48:20.853262Z","iopub.execute_input":"2022-07-29T19:48:20.853668Z","iopub.status.idle":"2022-07-29T19:48:20.905437Z","shell.execute_reply.started":"2022-07-29T19:48:20.853628Z","shell.execute_reply":"2022-07-29T19:48:20.904090Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"# Predicting Test Set\ny_hat_test_proba = reg.predict_proba(X_test_total[X_train_total.columns[rfe.support_]])\n# select the probabilities of only the positive class (class 1 - default) \ny_hat_test_proba = y_hat_test_proba[:][: , 1]\ny_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n# Rename the columns\ny_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba']\n# Makes the index of one dataframe equal to the index of another dataframe.\ny_test_proba.index = X_test.index\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:47:20.804360Z","iopub.execute_input":"2022-07-29T19:47:20.804764Z","iopub.status.idle":"2022-07-29T19:47:20.854480Z","shell.execute_reply.started":"2022-07-29T19:47:20.804732Z","shell.execute_reply":"2022-07-29T19:47:20.853017Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"# now finding the best threshold for our logistic regression model\nfpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], \n                                 y_test_proba['y_hat_test_proba'])\nauc_logistic = auc(fpr, tpr)\ni = np.arange(len(tpr)) \nroc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\nideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\nprint(\"Ideal logistic threshold is: \", ideal_roc_thresh['thresholds']) ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:52:41.195786Z","iopub.execute_input":"2022-07-29T19:52:41.197038Z","iopub.status.idle":"2022-07-29T19:52:41.230492Z","shell.execute_reply.started":"2022-07-29T19:52:41.196982Z","shell.execute_reply":"2022-07-29T19:52:41.228994Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"y_test_proba['y_hat_test_proba'] = np.where((y_test_proba['y_hat_test_proba'] >= 0.728379), 1, 0)\ny_test_proba","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:53:27.160017Z","iopub.execute_input":"2022-07-29T19:53:27.160463Z","iopub.status.idle":"2022-07-29T19:53:27.180134Z","shell.execute_reply.started":"2022-07-29T19:53:27.160430Z","shell.execute_reply":"2022-07-29T19:53:27.178194Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba']) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm, annot=True, fmt='g')","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:56:23.066453Z","iopub.execute_input":"2022-07-29T19:56:23.066853Z","iopub.status.idle":"2022-07-29T19:56:23.361821Z","shell.execute_reply.started":"2022-07-29T19:56:23.066821Z","shell.execute_reply":"2022-07-29T19:56:23.360300Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score ,recall_score ,f1_score\nacc = accuracy_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\nprec = precision_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\nrec = recall_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\nf1 = f1_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:57:55.748860Z","iopub.execute_input":"2022-07-29T19:57:55.749852Z","iopub.status.idle":"2022-07-29T19:57:55.895978Z","shell.execute_reply.started":"2022-07-29T19:57:55.749807Z","shell.execute_reply":"2022-07-29T19:57:55.894640Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"print(\"Test Data Accuracy: %0.4f\" % acc) \nprint(\"Test Data precision: %0.4f\" % prec) \nprint(\"Test Data recall: %0.4f\" % rec) \nprint(\"Test Data f1 score: %0.4f\" % f1) ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:57:59.542713Z","iopub.execute_input":"2022-07-29T19:57:59.543113Z","iopub.status.idle":"2022-07-29T19:57:59.551386Z","shell.execute_reply.started":"2022-07-29T19:57:59.543081Z","shell.execute_reply":"2022-07-29T19:57:59.549664Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"# plot the ROC curve\nplt.plot(fpr, tpr)\n# plot a secondary diagonal line, with dashed line style and black color to represent a no-skill classifier\nplt.plot(fpr, fpr, linestyle = '--', color = 'k')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve');","metadata":{"execution":{"iopub.status.busy":"2022-07-29T20:00:01.564499Z","iopub.execute_input":"2022-07-29T20:00:01.564891Z","iopub.status.idle":"2022-07-29T20:00:01.849120Z","shell.execute_reply.started":"2022-07-29T20:00:01.564846Z","shell.execute_reply":"2022-07-29T20:00:01.847676Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"# Calculate the Area Under the Receiver Operating Characteristic Curve (AUROC) on our test set\nAUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n# calculate Gini from AUROC\nGini = AUROC * 2 - 1\n# print AUROC and Gini\nprint('AUROC: %.4f' % (AUROC))\nprint('Gini: %.4f' % (Gini))","metadata":{"execution":{"iopub.status.busy":"2022-07-29T20:00:47.004943Z","iopub.execute_input":"2022-07-29T20:00:47.005371Z","iopub.status.idle":"2022-07-29T20:00:47.031407Z","shell.execute_reply.started":"2022-07-29T20:00:47.005340Z","shell.execute_reply":"2022-07-29T20:00:47.029781Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"# we now have astonishing results which is when we leave the model to choose its own features and select them it will get higher accuracy\n# but this needs very high computational power\n# when we choose our features using chi squared and annova and then do the engineering over them using WOE and IV \n# the results was :\n#Mean AUROC: 0.8624\n#Gini: 0.7248\n# Test Data Accuracy: 0.8009\n# but now the results are \n# AUROC: 0.9134\n# Gini: 0.8268\n# Test Data Accuracy: 0.9134","metadata":{"execution":{"iopub.status.busy":"2022-07-29T20:10:56.986507Z","iopub.execute_input":"2022-07-29T20:10:56.987183Z","iopub.status.idle":"2022-07-29T20:10:56.994218Z","shell.execute_reply.started":"2022-07-29T20:10:56.987136Z","shell.execute_reply":"2022-07-29T20:10:56.992835Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"# so now definetly if we make the model to choose the features automatically and giving us the features wich achieves the highest score \n# using the cross val score\n# this will definitely reach higher than 91% score cause we choose it randomly as 40 \n# but now using rfecv it will loop over all the feature numbers one by one from 0 till 118 and give us the best selection among them","metadata":{"execution":{"iopub.status.busy":"2022-07-29T20:10:57.522585Z","iopub.execute_input":"2022-07-29T20:10:57.522998Z","iopub.status.idle":"2022-07-29T20:10:57.530282Z","shell.execute_reply.started":"2022-07-29T20:10:57.522961Z","shell.execute_reply":"2022-07-29T20:10:57.528508Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"rfecv = RFECV(estimator = LogisticRegression(max_iter=5000 , class_weight = 'balanced',random_state=0), cv = 3, scoring = 'accuracy')\nmodel = LogisticRegression(max_iter=5000 , class_weight = 'balanced',random_state=0)\npipeline = Pipeline(steps = [('features', rfecv), ('model', model)])\ncv = RepeatedStratifiedKFold(n_splits = 3, n_repeats = 1, random_state = 1)\nscores = cross_val_score(pipeline, scaled_X_train_total, y_train, scoring = 'accuracy', cv = cv, n_jobs = -1)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T19:28:55.103891Z","iopub.execute_input":"2022-07-29T19:28:55.105051Z","iopub.status.idle":"2022-07-29T19:28:55.111367Z","shell.execute_reply.started":"2022-07-29T19:28:55.104990Z","shell.execute_reply":"2022-07-29T19:28:55.109836Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"#this takes very very very long time and didnt produce results which make me just write it but without results","metadata":{"execution":{"iopub.status.busy":"2022-07-29T20:11:02.448255Z","iopub.execute_input":"2022-07-29T20:11:02.449435Z","iopub.status.idle":"2022-07-29T20:11:02.455352Z","shell.execute_reply.started":"2022-07-29T20:11:02.449387Z","shell.execute_reply":"2022-07-29T20:11:02.453974Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"# thats the end of the task thank you for your support and code view time in advance\n# yours sincerely\n# fady elgawly","metadata":{"execution":{"iopub.status.busy":"2022-07-29T20:11:02.528561Z","iopub.execute_input":"2022-07-29T20:11:02.528873Z","iopub.status.idle":"2022-07-29T20:11:02.534626Z","shell.execute_reply.started":"2022-07-29T20:11:02.528845Z","shell.execute_reply":"2022-07-29T20:11:02.533306Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}